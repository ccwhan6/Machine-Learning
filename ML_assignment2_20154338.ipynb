{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Collecting torch==1.2.0+cpu\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torch-1.2.0%2Bcpu-cp37-cp37m-win_amd64.whl (89.4MB)\n",
      "Collecting torchvision==0.4.0+cpu\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torchvision-0.4.0%2Bcpu-cp37-cp37m-win_amd64.whl (684kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\ccwha\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from torch==1.2.0+cpu) (1.16.4)\n",
      "Collecting pillow>=4.1.1 (from torchvision==0.4.0+cpu)\n",
      "  Downloading https://files.pythonhosted.org/packages/ae/96/6f83deebfcd20a5d4ad35e4e989814a16559d8715741457e670aae1a5a09/Pillow-6.1.0-cp37-cp37m-win_amd64.whl (2.0MB)\n",
      "Requirement already satisfied: six in c:\\users\\ccwha\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from torchvision==0.4.0+cpu) (1.12.0)\n",
      "Installing collected packages: torch, pillow, torchvision\n",
      "Successfully installed pillow-6.1.0 torch-1.2.0+cpu torchvision-0.4.0+cpu\n"
     ]
    }
   ],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install torch==1.2.0+cpu torchvision==0.4.0+cpu -f https://download.pytorch.org/whl/torch_stable.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.59607846 0.59607846 0.59607846 ... 0.89411765 0.90196079 0.87450981]\n",
      " [0.60000002 0.59607846 0.60000002 ... 0.80784315 0.79215688 0.75294119]\n",
      " [0.6156863  0.6156863  0.6156863  ... 0.66274512 0.66274512 0.69803923]\n",
      " ...\n",
      " [0.35686275 0.35686275 0.35294119 ... 0.4627451  0.4627451  0.23529412]\n",
      " [0.35294119 0.35294119 0.34901962 ... 0.42352942 0.39607844 0.3882353 ]\n",
      " [0.35294119 0.34901962 0.34901962 ... 0.44313726 0.41568628 0.49411765]]\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " ...\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "[[1.         1.         1.         ... 1.         1.         1.        ]\n",
      " [1.         1.         1.         ... 1.         1.         1.        ]\n",
      " [1.         1.         1.         ... 1.         1.         1.        ]\n",
      " ...\n",
      " [1.         1.         1.         ... 0.99607843 1.         1.        ]\n",
      " [1.         1.         1.         ... 0.99607843 0.99607843 0.99607843]\n",
      " [1.         1.         1.         ... 0.99607843 0.99607843 0.99607843]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "transform = transforms.Compose([#transforms.Resize((256,256)),  \n",
    "                                transforms.Grayscale(),\t\t# the code transforms.Graysclae() is for changing the size [3,100,100] to [1, 100, 100] (notice : [channel, height, width] )\n",
    "                                transforms.ToTensor(),])\n",
    "\n",
    "\n",
    "#train_data_path = 'relative path of training data set'\n",
    "train_data_path = './horse-or-human/horse-or-human/train'\n",
    "trainset = torchvision.datasets.ImageFolder(root=train_data_path, transform=transform)\n",
    "# change the valuse of batch_size, num_workers for your program\n",
    "# if shuffle=True, the data reshuffled at every epoch \n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=3, shuffle=False, num_workers=1)  \n",
    "\n",
    "\n",
    "validation_data_path = './horse-or-human/horse-or-human/validation'\n",
    "valset = torchvision.datasets.ImageFolder(root=validation_data_path, transform=transform)\n",
    "# change the valuse of batch_size, num_workers for your program\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=3, shuffle=False, num_workers=1)\n",
    "\n",
    "train_data = np.zeros((1027,10000))\n",
    "val_data = np.zeros((256,10000))\n",
    "train_lab = np.zeros((1027,1))\n",
    "val_lab = np.zeros((1027,1))\n",
    "\n",
    "\n",
    "NUM_EPOCH = 1\n",
    "index = 0\n",
    "for epoch in range(0, NUM_EPOCH):\n",
    "    # load training images of the batch size for every iteration\n",
    "    for i, data in enumerate(trainloader):\n",
    "\n",
    "        # inputs is the image\n",
    "        # labels is the class of the image\n",
    "        inputs, labels = data\n",
    "\n",
    "        # if you don't change the image size, it will be [batch_size, 1, 100, 100]\n",
    "        #print(inputs)\n",
    "        #print(np.concatenate((temp[:1, :],labels[0]),axis = 0))\n",
    "\n",
    "        # if labels is horse it returns tensor[0,0,0] else it returns tensor[1,1,1]\n",
    "        lab_temp = labels.numpy() \n",
    "        for num in range(0, len(inputs)):\n",
    "            temp = inputs.view(len(inputs), -1)\n",
    "            temp = temp[num:num+1, :].numpy()\n",
    "            train_data[index] = temp[0]\n",
    "            train_lab[index] = lab_temp[num]\n",
    "            index += 1\n",
    "\n",
    "\n",
    "    index = 0\n",
    "\n",
    "    # load validation images of the batch size for every iteration\n",
    "    for i, data in enumerate(valloader):\n",
    "        \n",
    "        # inputs is the image\n",
    "        # labels is the class of the image\n",
    "        inputs, labels = data\n",
    "\n",
    "        # if you don't change the image size, it will be [batch_size, 1, 100, 100]\n",
    "        #print(inputs)\n",
    "\n",
    "        # if labels is horse it returns tensor[0,0,0] else it returns tensor[1,1,1]\n",
    "        #print(labels)    \n",
    "        \n",
    "        lab_temp = labels.numpy()\n",
    "        for num in range(0, len(inputs)):\n",
    "                temp = inputs.view(len(inputs), -1)\n",
    "                temp = temp[num:num+1, :].numpy()\n",
    "                val_data[index] = temp[0]\n",
    "                val_lab[index] = lab_temp[num]\n",
    "                index += 1\n",
    "        \n",
    "    print(val_data)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
