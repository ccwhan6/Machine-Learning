{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "class Linear(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=2):\n",
    "\n",
    "        super(Linear, self).__init__()\n",
    "\n",
    "        self.number_class   = num_classes\n",
    "\n",
    "        _size_image     = 100* 100\n",
    "        _num1           = 50\n",
    "        _num2           = 60\n",
    "        \n",
    "        self.fc1        = nn.Linear(_size_image, _num1, bias=True)\n",
    "        self.fc2        = nn.Linear(_num1, _num2, bias=True)\n",
    "        self.fc3        = nn.Linear(_num2, num_classes, bias=True)\n",
    "\n",
    "        self.fc_layer1  = nn.Sequential(self.fc1, nn.LeakyReLU(True))\n",
    "        self.fc_layer2  = nn.Sequential(self.fc2, nn.LeakyReLU(True))\n",
    "        self.fc_layer3  = nn.Sequential(self.fc3, nn.Sigmoid())\n",
    "        \n",
    "        self.classifier = nn.Sequential(self.fc_layer1, self.fc_layer2, self.fc_layer3)\n",
    "        \n",
    "        self._initialize_weight()        \n",
    "        \n",
    "    def _initialize_weight(self):\n",
    "\n",
    "        for name, m in self._modules.items():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                n = m.in_features\n",
    "                m.weight.data.uniform_(- 1.0 / math.sqrt(n), 1.0 / math.sqrt(n))\n",
    "\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime \n",
    "import csv\n",
    "import configparser\n",
    "import argparse\n",
    "import platform\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from random import shuffle\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# load dataset\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "transform = transforms.Compose([#transforms.Resize((256,256)),  \n",
    "                                transforms.Grayscale(),\t\t# the code transforms.Graysclae() is for changing the size [3,100,100] to [1, 100, 100] (notice : [channel, height, width] )\n",
    "                                transforms.ToTensor(),])\n",
    "\n",
    "\n",
    "#train_data_path = 'relative path of training data set'\n",
    "train_data_path = './horse-or-human/horse-or-human/train'\n",
    "trainset = torchvision.datasets.ImageFolder(root=train_data_path, transform=transform)\n",
    "# change the valuse of batch_size, num_workers for your program\n",
    "# if shuffle=True, the data reshuffled at every epoch \n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=3, shuffle=True, num_workers=1)  \n",
    "\n",
    "\n",
    "validation_data_path = './horse-or-human/horse-or-human/validation'\n",
    "valset = torchvision.datasets.ImageFolder(root=validation_data_path, transform=transform)\n",
    "# change the valuse of batch_size, num_workers for your program\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=3, shuffle=True, num_workers=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 0] loss: (training) 0.21917209799597867 , (testing) 0.18558936880435795 , accuracy: (training) 0.6105160662122687 ,    (testing) 74.609375\n",
      "[epoch 1] loss: (training) 0.19766214009160782 , (testing) 0.15269093750976026 , accuracy: (training) 0.7147030185004869 ,    (testing) 87.109375\n",
      "[epoch 2] loss: (training) 0.18334113506001098 , (testing) 0.15237864118535072 , accuracy: (training) 0.7546251217137293 ,    (testing) 86.71875\n",
      "[epoch 3] loss: (training) 0.17881103646303406 , (testing) 0.21603672951459885 , accuracy: (training) 0.7779941577409932 ,    (testing) 61.328125\n",
      "Epoch     4: reducing learning rate of group 0 to 1.5000e-03.\n",
      "[epoch 4] loss: (training) 0.17273381755002157 , (testing) 0.16047668259125203 , accuracy: (training) 0.7964946445959105 ,    (testing) 82.03125\n",
      "[epoch 5] loss: (training) 0.16253255882578294 , (testing) 0.15092049597296864 , accuracy: (training) 0.8393378773125608 ,    (testing) 85.15625\n",
      "[epoch 6] loss: (training) 0.15946532616462375 , (testing) 0.16279690864030272 , accuracy: (training) 0.8558909444985394 ,    (testing) 81.25\n",
      "Epoch     7: reducing learning rate of group 0 to 2.0000e-04.\n",
      "[epoch 7] loss: (training) 0.15892001974918635 , (testing) 0.15671979100443423 , accuracy: (training) 0.857838364167478 ,    (testing) 83.203125\n",
      "[epoch 8] loss: (training) 0.15776478198689087 , (testing) 0.15544330596458167 , accuracy: (training) 0.8597857838364168 ,    (testing) 84.765625\n",
      "[epoch 9] loss: (training) 0.1587766730982314 , (testing) 0.14961738232523203 , accuracy: (training) 0.8627069133398247 ,    (testing) 85.9375\n",
      "[epoch 10] loss: (training) 0.1575559190573104 , (testing) 0.14941134909167886 , accuracy: (training) 0.8597857838364168 ,    (testing) 86.328125\n",
      "[epoch 11] loss: (training) 0.15788093096313255 , (testing) 0.15191346919164062 , accuracy: (training) 0.8636806231742941 ,    (testing) 84.765625\n",
      "[epoch 12] loss: (training) 0.15853651193766136 , (testing) 0.1513575918506831 , accuracy: (training) 0.8636806231742941 ,    (testing) 84.765625\n",
      "[epoch 13] loss: (training) 0.15719575935248847 , (testing) 0.15067062026355416 , accuracy: (training) 0.8636806231742941 ,    (testing) 85.15625\n",
      "[epoch 14] loss: (training) 0.15809270707696707 , (testing) 0.15165690646972507 , accuracy: (training) 0.8656280428432327 ,    (testing) 84.765625\n",
      "[epoch 15] loss: (training) 0.15688892205556235 , (testing) 0.15117237088270485 , accuracy: (training) 0.8627069133398247 ,    (testing) 84.765625\n",
      "[epoch 16] loss: (training) 0.15821200895935036 , (testing) 0.15475645079277456 , accuracy: (training) 0.8636806231742941 ,    (testing) 84.765625\n",
      "[epoch 17] loss: (training) 0.15681283817462718 , (testing) 0.14969432610087097 , accuracy: (training) 0.8617332035053554 ,    (testing) 85.9375\n",
      "[epoch 18] loss: (training) 0.15713651123501007 , (testing) 0.15079731936566532 , accuracy: (training) 0.8646543330087634 ,    (testing) 84.765625\n",
      "[epoch 19] loss: (training) 0.15681506182176608 , (testing) 0.15287458209786564 , accuracy: (training) 0.8656280428432327 ,    (testing) 84.765625\n",
      "[epoch 20] loss: (training) 0.15627837818264384 , (testing) 0.14988716575317085 , accuracy: (training) 0.8685491723466408 ,    (testing) 85.9375\n",
      "[epoch 21] loss: (training) 0.15622810748622065 , (testing) 0.14972233842127025 , accuracy: (training) 0.8646543330087634 ,    (testing) 85.9375\n",
      "[epoch 22] loss: (training) 0.15638809220320513 , (testing) 0.14969893114175647 , accuracy: (training) 0.866601752677702 ,    (testing) 85.9375\n",
      "[epoch 23] loss: (training) 0.15694690949715262 , (testing) 0.1532060692552477 , accuracy: (training) 0.8656280428432327 ,    (testing) 85.15625\n",
      "[epoch 24] loss: (training) 0.1559986827208998 , (testing) 0.15142773371189833 , accuracy: (training) 0.8646543330087634 ,    (testing) 85.15625\n",
      "[epoch 25] loss: (training) 0.1574785726468927 , (testing) 0.15105425426736474 , accuracy: (training) 0.866601752677702 ,    (testing) 84.765625\n",
      "[epoch 26] loss: (training) 0.15576091011944504 , (testing) 0.1522216701414436 , accuracy: (training) 0.8695228821811101 ,    (testing) 84.765625\n",
      "[epoch 27] loss: (training) 0.15818471785189459 , (testing) 0.15263049700297415 , accuracy: (training) 0.8695228821811101 ,    (testing) 84.765625\n",
      "[epoch 28] loss: (training) 0.15608552576154036 , (testing) 0.15206379105802625 , accuracy: (training) 0.8714703018500487 ,    (testing) 84.765625\n",
      "[epoch 29] loss: (training) 0.15624688193564049 , (testing) 0.15157445869408548 , accuracy: (training) 0.8675754625121713 ,    (testing) 85.15625\n",
      "[epoch 30] loss: (training) 0.15531232118954116 , (testing) 0.14950114442035556 , accuracy: (training) 0.8704965920155794 ,    (testing) 85.9375\n",
      "[epoch 31] loss: (training) 0.15547281920736108 , (testing) 0.1489185009850189 , accuracy: (training) 0.875365141187926 ,    (testing) 86.71875\n",
      "[epoch 32] loss: (training) 0.15515843725992243 , (testing) 0.1531346543924883 , accuracy: (training) 0.8734177215189873 ,    (testing) 84.765625\n",
      "[epoch 33] loss: (training) 0.15509668285112221 , (testing) 0.15336753451265395 , accuracy: (training) 0.8734177215189873 ,    (testing) 84.375\n",
      "[epoch 34] loss: (training) 0.15750568705467025 , (testing) 0.15049399994313717 , accuracy: (training) 0.8773125608568647 ,    (testing) 85.15625\n",
      "[epoch 35] loss: (training) 0.15537001405443465 , (testing) 0.15242597472388297 , accuracy: (training) 0.8734177215189873 ,    (testing) 84.765625\n",
      "[epoch 36] loss: (training) 0.15482915499119995 , (testing) 0.15156537492293864 , accuracy: (training) 0.878286270691334 ,    (testing) 84.765625\n",
      "[epoch 37] loss: (training) 0.1549842781065968 , (testing) 0.1524070028681308 , accuracy: (training) 0.875365141187926 ,    (testing) 84.765625\n",
      "[epoch 38] loss: (training) 0.15503291210813122 , (testing) 0.15228866727557033 , accuracy: (training) 0.878286270691334 ,    (testing) 84.765625\n",
      "[epoch 39] loss: (training) 0.15525517400546024 , (testing) 0.1513491147197783 , accuracy: (training) 0.878286270691334 ,    (testing) 84.765625\n",
      "[epoch 40] loss: (training) 0.15476318521912058 , (testing) 0.15174832672346383 , accuracy: (training) 0.8763388510223953 ,    (testing) 85.15625\n",
      "[epoch 41] loss: (training) 0.15424730287696461 , (testing) 0.15318246942479163 , accuracy: (training) 0.875365141187926 ,    (testing) 84.375\n",
      "[epoch 42] loss: (training) 0.15419419033070927 , (testing) 0.15335652930662036 , accuracy: (training) 0.8763388510223953 ,    (testing) 84.375\n",
      "[epoch 43] loss: (training) 0.15413371730592207 , (testing) 0.15301645186264068 , accuracy: (training) 0.8773125608568647 ,    (testing) 83.984375\n",
      "[epoch 44] loss: (training) 0.15395495179674948 , (testing) 0.1499586704885587 , accuracy: (training) 0.8792599805258033 ,    (testing) 85.546875\n",
      "[epoch 45] loss: (training) 0.15390782523085703 , (testing) 0.15513150987681001 , accuracy: (training) 0.875365141187926 ,    (testing) 82.8125\n",
      "[epoch 46] loss: (training) 0.15397195806192818 , (testing) 0.15359433949925005 , accuracy: (training) 0.8802336903602727 ,    (testing) 84.375\n",
      "[epoch 47] loss: (training) 0.15425058889435378 , (testing) 0.15303647879045457 , accuracy: (training) 0.8743914313534566 ,    (testing) 83.984375\n",
      "[epoch 48] loss: (training) 0.15401900808016458 , (testing) 0.15092316712252796 , accuracy: (training) 0.878286270691334 ,    (testing) 85.15625\n",
      "[epoch 49] loss: (training) 0.15380974465834504 , (testing) 0.1501660948852077 , accuracy: (training) 0.8821811100292113 ,    (testing) 85.15625\n",
      "[epoch 50] loss: (training) 0.15403428103184677 , (testing) 0.1536873906152323 , accuracy: (training) 0.881207400194742 ,    (testing) 83.984375\n",
      "[epoch 51] loss: (training) 0.1536635123084655 , (testing) 0.14927921735215932 , accuracy: (training) 0.8821811100292113 ,    (testing) 85.9375\n",
      "[epoch 52] loss: (training) 0.15331141655021088 , (testing) 0.15482918545603752 , accuracy: (training) 0.8802336903602727 ,    (testing) 83.984375\n",
      "[epoch 53] loss: (training) 0.15351115443732 , (testing) 0.14976315945386887 , accuracy: (training) 0.8851022395326192 ,    (testing) 85.9375\n",
      "[epoch 54] loss: (training) 0.153466911803645 , (testing) 0.15619472705293447 , accuracy: (training) 0.887049659201558 ,    (testing) 82.03125\n",
      "[epoch 55] loss: (training) 0.15358956521639439 , (testing) 0.150971133611165 , accuracy: (training) 0.8821811100292113 ,    (testing) 85.15625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 56] loss: (training) 0.15287885906860826 , (testing) 0.151406251010485 , accuracy: (training) 0.8851022395326192 ,    (testing) 84.765625\n",
      "[epoch 57] loss: (training) 0.1528524754693835 , (testing) 0.15139210980851203 , accuracy: (training) 0.8841285296981499 ,    (testing) 84.765625\n",
      "[epoch 58] loss: (training) 0.15276110068007043 , (testing) 0.15629911608994007 , accuracy: (training) 0.8831548198636806 ,    (testing) 82.03125\n",
      "[epoch 59] loss: (training) 0.15275961285198164 , (testing) 0.15585563087370247 , accuracy: (training) 0.8821811100292113 ,    (testing) 83.203125\n",
      "[epoch 60] loss: (training) 0.1526060685935359 , (testing) 0.15354278474114835 , accuracy: (training) 0.8860759493670886 ,    (testing) 83.984375\n",
      "[epoch 61] loss: (training) 0.1523941448003604 , (testing) 0.14839531620964408 , accuracy: (training) 0.8841285296981499 ,    (testing) 87.109375\n",
      "[epoch 62] loss: (training) 0.152549750835022 , (testing) 0.15238131512887776 , accuracy: (training) 0.8831548198636806 ,    (testing) 84.375\n",
      "[epoch 63] loss: (training) 0.15329859428201867 , (testing) 0.15321364463306963 , accuracy: (training) 0.8860759493670886 ,    (testing) 83.984375\n",
      "[epoch 64] loss: (training) 0.1522772973086558 , (testing) 0.15328267682343721 , accuracy: (training) 0.8860759493670886 ,    (testing) 83.984375\n",
      "[epoch 65] loss: (training) 0.15212292177104855 , (testing) 0.15316934220027179 , accuracy: (training) 0.8821811100292113 ,    (testing) 83.59375\n",
      "[epoch 66] loss: (training) 0.15207847173753816 , (testing) 0.14986502390820533 , accuracy: (training) 0.8841285296981499 ,    (testing) 85.9375\n",
      "[epoch 67] loss: (training) 0.15236809991654898 , (testing) 0.15126825799234211 , accuracy: (training) 0.8841285296981499 ,    (testing) 84.765625\n",
      "[epoch 68] loss: (training) 0.15203551277590677 , (testing) 0.151333317742683 , accuracy: (training) 0.881207400194742 ,    (testing) 84.765625\n",
      "[epoch 69] loss: (training) 0.15181016974129413 , (testing) 0.1551622322294861 , accuracy: (training) 0.887049659201558 ,    (testing) 83.59375\n",
      "[epoch 70] loss: (training) 0.15169753662814667 , (testing) 0.15243513986933976 , accuracy: (training) 0.8899707887049659 ,    (testing) 83.984375\n",
      "[epoch 71] loss: (training) 0.1516535890924919 , (testing) 0.1523264654679224 , accuracy: (training) 0.8860759493670886 ,    (testing) 84.765625\n",
      "[epoch 72] loss: (training) 0.15169528989796505 , (testing) 0.15378568856976926 , accuracy: (training) 0.8851022395326192 ,    (testing) 83.59375\n",
      "[epoch 73] loss: (training) 0.15215802042083446 , (testing) 0.14953318273182958 , accuracy: (training) 0.887049659201558 ,    (testing) 86.328125\n",
      "[epoch 74] loss: (training) 0.151403845138522 , (testing) 0.1529790562344715 , accuracy: (training) 0.8841285296981499 ,    (testing) 83.59375\n",
      "[epoch 75] loss: (training) 0.1528427102996726 , (testing) 0.15078754350543022 , accuracy: (training) 0.8851022395326192 ,    (testing) 85.15625\n",
      "[epoch 76] loss: (training) 0.15142545735407384 , (testing) 0.1508539585629478 , accuracy: (training) 0.8851022395326192 ,    (testing) 84.765625\n",
      "[epoch 77] loss: (training) 0.1519889920457575 , (testing) 0.15308300266042352 , accuracy: (training) 0.8860759493670886 ,    (testing) 83.59375\n",
      "[epoch 78] loss: (training) 0.15105355032099696 , (testing) 0.15095288248267025 , accuracy: (training) 0.8880233690360273 ,    (testing) 85.15625\n",
      "[epoch 79] loss: (training) 0.15148599815090613 , (testing) 0.15334537695161998 , accuracy: (training) 0.887049659201558 ,    (testing) 83.59375\n",
      "[epoch 80] loss: (training) 0.15109798772689553 , (testing) 0.1523173482855782 , accuracy: (training) 0.8860759493670886 ,    (testing) 83.59375\n",
      "[epoch 81] loss: (training) 0.15154610703128188 , (testing) 0.15599621238652617 , accuracy: (training) 0.887049659201558 ,    (testing) 81.640625\n",
      "[epoch 82] loss: (training) 0.15080109264690741 , (testing) 0.15254632208961993 , accuracy: (training) 0.887049659201558 ,    (testing) 83.59375\n",
      "[epoch 83] loss: (training) 0.15102050029849173 , (testing) 0.1553464042954147 , accuracy: (training) 0.887049659201558 ,    (testing) 83.59375\n",
      "[epoch 84] loss: (training) 0.150758293934304 , (testing) 0.14992742286995053 , accuracy: (training) 0.887049659201558 ,    (testing) 85.9375\n",
      "[epoch 85] loss: (training) 0.15072857059241498 , (testing) 0.1532510439865291 , accuracy: (training) 0.8889970788704966 ,    (testing) 83.203125\n",
      "[epoch 86] loss: (training) 0.15032834970221226 , (testing) 0.14972815779037774 , accuracy: (training) 0.8919182083739046 ,    (testing) 85.546875\n",
      "[epoch 87] loss: (training) 0.15040171227487578 , (testing) 0.15405557258054614 , accuracy: (training) 0.8899707887049659 ,    (testing) 83.203125\n",
      "[epoch 88] loss: (training) 0.1502949201272922 , (testing) 0.15461259754374623 , accuracy: (training) 0.8880233690360273 ,    (testing) 83.203125\n",
      "[epoch 89] loss: (training) 0.1503457463227857 , (testing) 0.15618327667471021 , accuracy: (training) 0.8880233690360273 ,    (testing) 81.640625\n",
      "[epoch 90] loss: (training) 0.15086773304364656 , (testing) 0.1537315013119951 , accuracy: (training) 0.8919182083739046 ,    (testing) 83.59375\n",
      "[epoch 91] loss: (training) 0.1500590504432211 , (testing) 0.15347810578532517 , accuracy: (training) 0.8909444985394352 ,    (testing) 83.203125\n",
      "[epoch 92] loss: (training) 0.1497429427125132 , (testing) 0.15092790790367872 , accuracy: (training) 0.8919182083739046 ,    (testing) 85.15625\n",
      "[epoch 93] loss: (training) 0.1522391844537214 , (testing) 0.15365031186956912 , accuracy: (training) 0.887049659201558 ,    (testing) 83.59375\n",
      "[epoch 94] loss: (training) 0.1498172544992816 , (testing) 0.15500264067668468 , accuracy: (training) 0.8899707887049659 ,    (testing) 82.03125\n",
      "[epoch 95] loss: (training) 0.14972572177793358 , (testing) 0.15145742264576256 , accuracy: (training) 0.8919182083739046 ,    (testing) 84.375\n",
      "[epoch 96] loss: (training) 0.14987633782063328 , (testing) 0.1535585824167356 , accuracy: (training) 0.8889970788704966 ,    (testing) 83.59375\n",
      "[epoch 97] loss: (training) 0.1496367995836297 , (testing) 0.15659460285678506 , accuracy: (training) 0.8919182083739046 ,    (testing) 81.640625\n",
      "[epoch 98] loss: (training) 0.1501366259463211 , (testing) 0.1542530582519248 , accuracy: (training) 0.8919182083739046 ,    (testing) 83.984375\n",
      "[epoch 99] loss: (training) 0.1518961472692017 , (testing) 0.15540877217426896 , accuracy: (training) 0.8928919182083739 ,    (testing) 82.03125\n",
      "[epoch 100] loss: (training) 0.14926770532212288 , (testing) 0.1517608700087294 , accuracy: (training) 0.8938656280428432 ,    (testing) 84.375\n",
      "[epoch 101] loss: (training) 0.1491230582878124 , (testing) 0.1520450602984056 , accuracy: (training) 0.8928919182083739 ,    (testing) 85.9375\n",
      "[epoch 102] loss: (training) 0.1496000822825381 , (testing) 0.1513693886809051 , accuracy: (training) 0.8958130477117819 ,    (testing) 84.375\n",
      "[epoch 103] loss: (training) 0.14899424717655682 , (testing) 0.1531859749229625 , accuracy: (training) 0.8967867575462513 ,    (testing) 83.203125\n",
      "[epoch 104] loss: (training) 0.1493578907120448 , (testing) 0.14986764220520854 , accuracy: (training) 0.8948393378773125 ,    (testing) 85.9375\n",
      "[epoch 105] loss: (training) 0.14941415399226085 , (testing) 0.15116098592989147 , accuracy: (training) 0.8958130477117819 ,    (testing) 84.765625\n",
      "[epoch 106] loss: (training) 0.1489680282576091 , (testing) 0.15378142660483718 , accuracy: (training) 0.8919182083739046 ,    (testing) 83.984375\n",
      "[epoch 107] loss: (training) 0.14951582801816993 , (testing) 0.15748847101349384 , accuracy: (training) 0.8948393378773125 ,    (testing) 81.640625\n",
      "[epoch 108] loss: (training) 0.148922312450826 , (testing) 0.15477823524270207 , accuracy: (training) 0.8958130477117819 ,    (testing) 82.03125\n",
      "[epoch 109] loss: (training) 0.1490290508152097 , (testing) 0.15033911645878106 , accuracy: (training) 0.8928919182083739 ,    (testing) 85.9375\n",
      "[epoch 110] loss: (training) 0.14868170570354072 , (testing) 0.15289384010247886 , accuracy: (training) 0.8967867575462513 ,    (testing) 83.59375\n",
      "[epoch 111] loss: (training) 0.14865749040428472 , (testing) 0.15139015100430697 , accuracy: (training) 0.8967867575462513 ,    (testing) 84.765625\n",
      "[epoch 112] loss: (training) 0.14939930997390674 , (testing) 0.15571767394430935 , accuracy: (training) 0.8948393378773125 ,    (testing) 82.421875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 113] loss: (training) 0.148459455622876 , (testing) 0.15146819490473717 , accuracy: (training) 0.8928919182083739 ,    (testing) 85.15625\n",
      "[epoch 114] loss: (training) 0.14873855776063902 , (testing) 0.15126525214873254 , accuracy: (training) 0.8958130477117819 ,    (testing) 85.15625\n",
      "[epoch 115] loss: (training) 0.1487805593118028 , (testing) 0.15323730546515435 , accuracy: (training) 0.8977604673807206 ,    (testing) 82.421875\n",
      "[epoch 116] loss: (training) 0.14820488053577635 , (testing) 0.15361764922272414 , accuracy: (training) 0.8958130477117819 ,    (testing) 82.421875\n",
      "[epoch 117] loss: (training) 0.14788141212379968 , (testing) 0.15594801132101566 , accuracy: (training) 0.8977604673807206 ,    (testing) 82.03125\n",
      "[epoch 118] loss: (training) 0.1482943096012601 , (testing) 0.1497703093336895 , accuracy: (training) 0.9016553067185978 ,    (testing) 86.71875\n",
      "[epoch 119] loss: (training) 0.1479451055371495 , (testing) 0.15270048682577908 , accuracy: (training) 0.8948393378773125 ,    (testing) 83.984375\n",
      "[epoch 120] loss: (training) 0.14901537997729578 , (testing) 0.15372814307920635 , accuracy: (training) 0.8987341772151899 ,    (testing) 84.765625\n",
      "[epoch 121] loss: (training) 0.14779005798468667 , (testing) 0.1537098140688613 , accuracy: (training) 0.8958130477117819 ,    (testing) 82.421875\n",
      "[epoch 122] loss: (training) 0.1476579822013399 , (testing) 0.1554936917964369 , accuracy: (training) 0.8977604673807206 ,    (testing) 82.03125\n",
      "[epoch 123] loss: (training) 0.14834422159820534 , (testing) 0.1522265411913395 , accuracy: (training) 0.9006815968841285 ,    (testing) 84.375\n",
      "[epoch 124] loss: (training) 0.14746166935119961 , (testing) 0.15288942446932197 , accuracy: (training) 0.9016553067185978 ,    (testing) 84.375\n",
      "[epoch 125] loss: (training) 0.1474566917261878 , (testing) 0.1533892813604325 , accuracy: (training) 0.9006815968841285 ,    (testing) 82.421875\n",
      "[epoch 126] loss: (training) 0.14754869430475262 , (testing) 0.1557975832838565 , accuracy: (training) 0.9016553067185978 ,    (testing) 82.03125\n",
      "[epoch 127] loss: (training) 0.14751336508520144 , (testing) 0.15318027138710022 , accuracy: (training) 0.8997078870496592 ,    (testing) 83.203125\n",
      "[epoch 128] loss: (training) 0.14744970723769407 , (testing) 0.15412799175828695 , accuracy: (training) 0.8987341772151899 ,    (testing) 82.8125\n",
      "[epoch 129] loss: (training) 0.14705169641125884 , (testing) 0.15022487950045615 , accuracy: (training) 0.9006815968841285 ,    (testing) 86.328125\n",
      "[epoch 130] loss: (training) 0.14729251191961293 , (testing) 0.15254662686493248 , accuracy: (training) 0.9026290165530672 ,    (testing) 84.375\n",
      "[epoch 131] loss: (training) 0.14701327354266183 , (testing) 0.15243145416025072 , accuracy: (training) 0.9036027263875365 ,    (testing) 85.15625\n",
      "[epoch 132] loss: (training) 0.14686487153158012 , (testing) 0.15520570485386997 , accuracy: (training) 0.9036027263875365 ,    (testing) 82.03125\n",
      "[epoch 133] loss: (training) 0.14715183809385124 , (testing) 0.15214373427443206 , accuracy: (training) 0.9036027263875365 ,    (testing) 84.765625\n",
      "[epoch 134] loss: (training) 0.14675897058638934 , (testing) 0.15879186487291008 , accuracy: (training) 0.9036027263875365 ,    (testing) 81.25\n",
      "[epoch 135] loss: (training) 0.14719736567391598 , (testing) 0.15313971869181842 , accuracy: (training) 0.9036027263875365 ,    (testing) 83.59375\n",
      "[epoch 136] loss: (training) 0.14679705749100222 , (testing) 0.15131588513031602 , accuracy: (training) 0.9074975657254138 ,    (testing) 84.765625\n",
      "[epoch 137] loss: (training) 0.14722095752828204 , (testing) 0.15189260768238455 , accuracy: (training) 0.9074975657254138 ,    (testing) 84.765625\n",
      "[epoch 138] loss: (training) 0.14712685792624547 , (testing) 0.15608648606576025 , accuracy: (training) 0.9065238558909445 ,    (testing) 82.03125\n",
      "[epoch 139] loss: (training) 0.14650011630285356 , (testing) 0.1531349099241197 , accuracy: (training) 0.9065238558909445 ,    (testing) 83.59375\n",
      "[epoch 140] loss: (training) 0.14639784930051242 , (testing) 0.15100740711204708 , accuracy: (training) 0.9065238558909445 ,    (testing) 85.15625\n",
      "[epoch 141] loss: (training) 0.1462663716778695 , (testing) 0.15379465837031603 , accuracy: (training) 0.9074975657254138 ,    (testing) 85.15625\n",
      "[epoch 142] loss: (training) 0.14635833588123787 , (testing) 0.1511520268395543 , accuracy: (training) 0.9055501460564752 ,    (testing) 85.15625\n",
      "[epoch 143] loss: (training) 0.14645183500557762 , (testing) 0.15891002188436687 , accuracy: (training) 0.9084712755598832 ,    (testing) 80.46875\n",
      "[epoch 144] loss: (training) 0.1460777480006797 , (testing) 0.15824183472432196 , accuracy: (training) 0.9055501460564752 ,    (testing) 80.46875\n",
      "[epoch 145] loss: (training) 0.14602904034773045 , (testing) 0.15682108351029456 , accuracy: (training) 0.9094449853943525 ,    (testing) 81.640625\n",
      "[epoch 146] loss: (training) 0.14597454226862702 , (testing) 0.15233209042344242 , accuracy: (training) 0.9065238558909445 ,    (testing) 84.375\n",
      "[epoch 147] loss: (training) 0.14588300297281137 , (testing) 0.15185765305068344 , accuracy: (training) 0.9055501460564752 ,    (testing) 85.15625\n",
      "[epoch 148] loss: (training) 0.1458486408082111 , (testing) 0.15366263419855386 , accuracy: (training) 0.9074975657254138 ,    (testing) 83.203125\n",
      "[epoch 149] loss: (training) 0.1461309238008438 , (testing) 0.15521813288796693 , accuracy: (training) 0.9084712755598832 ,    (testing) 83.203125\n",
      "[epoch 150] loss: (training) 0.1463159840586582 , (testing) 0.15467739605810493 , accuracy: (training) 0.9074975657254138 ,    (testing) 82.8125\n",
      "[epoch 151] loss: (training) 0.14564126973249475 , (testing) 0.15472100349143147 , accuracy: (training) 0.9094449853943525 ,    (testing) 84.375\n",
      "[epoch 152] loss: (training) 0.14582665468791484 , (testing) 0.15182189154438674 , accuracy: (training) 0.9094449853943525 ,    (testing) 85.15625\n",
      "[epoch 153] loss: (training) 0.145417478648752 , (testing) 0.15091167017817497 , accuracy: (training) 0.9104186952288218 ,    (testing) 85.546875\n",
      "[epoch 154] loss: (training) 0.14550836518971635 , (testing) 0.15455248532816768 , accuracy: (training) 0.9084712755598832 ,    (testing) 84.765625\n",
      "[epoch 155] loss: (training) 0.14559946208468216 , (testing) 0.15316800132859498 , accuracy: (training) 0.9094449853943525 ,    (testing) 84.375\n",
      "[epoch 156] loss: (training) 0.14677246660718188 , (testing) 0.15768401662353426 , accuracy: (training) 0.9104186952288218 ,    (testing) 80.46875\n",
      "[epoch 157] loss: (training) 0.14518460214311804 , (testing) 0.1497104992158711 , accuracy: (training) 0.9104186952288218 ,    (testing) 87.5\n",
      "[epoch 158] loss: (training) 0.14512307419142062 , (testing) 0.15761279047001153 , accuracy: (training) 0.9133398247322297 ,    (testing) 82.03125\n",
      "[epoch 159] loss: (training) 0.1454035083974184 , (testing) 0.1536049909191206 , accuracy: (training) 0.9074975657254138 ,    (testing) 84.375\n",
      "[epoch 160] loss: (training) 0.14510309922104328 , (testing) 0.15410961210727692 , accuracy: (training) 0.9113924050632911 ,    (testing) 84.375\n",
      "[epoch 161] loss: (training) 0.1449220780033412 , (testing) 0.15569184871856123 , accuracy: (training) 0.9094449853943525 ,    (testing) 82.03125\n",
      "[epoch 162] loss: (training) 0.14577980303324117 , (testing) 0.15345798525959253 , accuracy: (training) 0.9123661148977604 ,    (testing) 83.984375\n",
      "[epoch 163] loss: (training) 0.14470375852751663 , (testing) 0.1533227419713512 , accuracy: (training) 0.9123661148977604 ,    (testing) 86.328125\n",
      "[epoch 164] loss: (training) 0.14480257138566444 , (testing) 0.1550976608414203 , accuracy: (training) 0.9104186952288218 ,    (testing) 83.984375\n",
      "[epoch 165] loss: (training) 0.14478232251775275 , (testing) 0.15753826522268355 , accuracy: (training) 0.9123661148977604 ,    (testing) 81.640625\n",
      "[epoch 166] loss: (training) 0.14463632832579063 , (testing) 0.15531585027929395 , accuracy: (training) 0.9113924050632911 ,    (testing) 82.03125\n",
      "[epoch 167] loss: (training) 0.14457933539551826 , (testing) 0.15359401633031666 , accuracy: (training) 0.9143135345666992 ,    (testing) 83.984375\n",
      "[epoch 168] loss: (training) 0.14452431318363712 , (testing) 0.1556588839739561 , accuracy: (training) 0.9152872444011685 ,    (testing) 82.03125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 169] loss: (training) 0.144454124283165 , (testing) 0.15786303742788732 , accuracy: (training) 0.9133398247322297 ,    (testing) 80.46875\n",
      "[epoch 170] loss: (training) 0.1444171902273788 , (testing) 0.15334802167490125 , accuracy: (training) 0.9123661148977604 ,    (testing) 84.375\n",
      "[epoch 171] loss: (training) 0.14474016653900593 , (testing) 0.15344935143366456 , accuracy: (training) 0.9104186952288218 ,    (testing) 84.375\n",
      "[epoch 172] loss: (training) 0.1441805732841047 , (testing) 0.15576600166969 , accuracy: (training) 0.9104186952288218 ,    (testing) 82.8125\n",
      "[epoch 173] loss: (training) 0.14414947619706941 , (testing) 0.1524863630766049 , accuracy: (training) 0.9152872444011685 ,    (testing) 85.15625\n",
      "[epoch 174] loss: (training) 0.14425070840137694 , (testing) 0.15519708779174834 , accuracy: (training) 0.9133398247322297 ,    (testing) 82.8125\n",
      "[epoch 175] loss: (training) 0.14413640265098696 , (testing) 0.15280309552326798 , accuracy: (training) 0.9133398247322297 ,    (testing) 85.546875\n",
      "[epoch 176] loss: (training) 0.14389380340557636 , (testing) 0.15367148048244417 , accuracy: (training) 0.9104186952288218 ,    (testing) 85.15625\n",
      "[epoch 177] loss: (training) 0.14402970752748503 , (testing) 0.15727410453837365 , accuracy: (training) 0.9172346640701071 ,    (testing) 81.25\n",
      "[epoch 178] loss: (training) 0.1438661998226529 , (testing) 0.15936188050545752 , accuracy: (training) 0.9143135345666992 ,    (testing) 81.25\n",
      "[epoch 179] loss: (training) 0.14389250183476188 , (testing) 0.15870109491515905 , accuracy: (training) 0.9143135345666992 ,    (testing) 80.46875\n",
      "[epoch 180] loss: (training) 0.1461228717867904 , (testing) 0.1560815202537924 , accuracy: (training) 0.9162609542356378 ,    (testing) 81.640625\n",
      "[epoch 181] loss: (training) 0.14434177204749327 , (testing) 0.15936721256002784 , accuracy: (training) 0.9162609542356378 ,    (testing) 80.46875\n",
      "[epoch 182] loss: (training) 0.14453040901843034 , (testing) 0.16160104097798467 , accuracy: (training) 0.9172346640701071 ,    (testing) 80.46875\n",
      "[epoch 183] loss: (training) 0.14361849566242785 , (testing) 0.15812763152644038 , accuracy: (training) 0.9172346640701071 ,    (testing) 80.46875\n",
      "[epoch 184] loss: (training) 0.14355239642836493 , (testing) 0.15454341983422637 , accuracy: (training) 0.9152872444011685 ,    (testing) 83.203125\n",
      "[epoch 185] loss: (training) 0.1433942046295218 , (testing) 0.15800479368772358 , accuracy: (training) 0.9133398247322297 ,    (testing) 81.25\n",
      "[epoch 186] loss: (training) 0.1433429393638559 , (testing) 0.1610867689596489 , accuracy: (training) 0.9143135345666992 ,    (testing) 79.296875\n",
      "[epoch 187] loss: (training) 0.1438315338713087 , (testing) 0.15368108602706343 , accuracy: (training) 0.9152872444011685 ,    (testing) 83.984375\n",
      "[epoch 188] loss: (training) 0.14371092685573417 , (testing) 0.15273975068703294 , accuracy: (training) 0.9162609542356378 ,    (testing) 85.15625\n",
      "[epoch 189] loss: (training) 0.1441519351058845 , (testing) 0.16363377845846117 , accuracy: (training) 0.9143135345666992 ,    (testing) 78.90625\n",
      "[epoch 190] loss: (training) 0.1432238999678164 , (testing) 0.15452413423918188 , accuracy: (training) 0.9152872444011685 ,    (testing) 83.203125\n",
      "[epoch 191] loss: (training) 0.14274881752633262 , (testing) 0.16043859452474862 , accuracy: (training) 0.9191820837390458 ,    (testing) 80.46875\n",
      "[epoch 192] loss: (training) 0.1429500686415662 , (testing) 0.15148743521422148 , accuracy: (training) 0.9143135345666992 ,    (testing) 85.9375\n",
      "[epoch 193] loss: (training) 0.1436932054506678 , (testing) 0.157907695742324 , accuracy: (training) 0.9191820837390458 ,    (testing) 81.25\n",
      "[epoch 194] loss: (training) 0.1428262364296686 , (testing) 0.16019441129174083 , accuracy: (training) 0.9191820837390458 ,    (testing) 80.46875\n",
      "[epoch 195] loss: (training) 0.14310338913641354 , (testing) 0.15656593372114003 , accuracy: (training) 0.9162609542356378 ,    (testing) 81.640625\n",
      "[epoch 196] loss: (training) 0.14271349450473766 , (testing) 0.15166004141792655 , accuracy: (training) 0.9191820837390458 ,    (testing) 85.546875\n",
      "[epoch 197] loss: (training) 0.14277484538024554 , (testing) 0.15782138262875378 , accuracy: (training) 0.9162609542356378 ,    (testing) 81.25\n",
      "[epoch 198] loss: (training) 0.14268664530577074 , (testing) 0.15252443810459226 , accuracy: (training) 0.9172346640701071 ,    (testing) 85.15625\n",
      "[epoch 199] loss: (training) 0.1437490386100969 , (testing) 0.1597825906937942 , accuracy: (training) 0.9152872444011685 ,    (testing) 80.46875\n",
      "[epoch 200] loss: (training) 0.14261887896628608 , (testing) 0.15654328279197216 , accuracy: (training) 0.9152872444011685 ,    (testing) 83.203125\n",
      "[epoch 201] loss: (training) 0.14284978646231114 , (testing) 0.16077888547442853 , accuracy: (training) 0.9162609542356378 ,    (testing) 80.859375\n",
      "[epoch 202] loss: (training) 0.1422885452171804 , (testing) 0.1540006916038692 , accuracy: (training) 0.9201557935735151 ,    (testing) 84.765625\n",
      "[epoch 203] loss: (training) 0.14259913476841096 , (testing) 0.15175053454004228 , accuracy: (training) 0.9211295034079844 ,    (testing) 85.546875\n",
      "[epoch 204] loss: (training) 0.14482210537435014 , (testing) 0.15519437449984252 , accuracy: (training) 0.9172346640701071 ,    (testing) 83.203125\n",
      "[epoch 205] loss: (training) 0.14272849396435933 , (testing) 0.1531662109773606 , accuracy: (training) 0.9162609542356378 ,    (testing) 84.765625\n",
      "[epoch 206] loss: (training) 0.1425501563458679 , (testing) 0.1540962812723592 , accuracy: (training) 0.9172346640701071 ,    (testing) 83.984375\n",
      "[epoch 207] loss: (training) 0.1420638640026541 , (testing) 0.15825496590696275 , accuracy: (training) 0.9191820837390458 ,    (testing) 81.25\n",
      "[epoch 208] loss: (training) 0.14260796897033678 , (testing) 0.1556838935939595 , accuracy: (training) 0.9211295034079844 ,    (testing) 82.8125\n",
      "[epoch 209] loss: (training) 0.14257281789858442 , (testing) 0.15140042989514768 , accuracy: (training) 0.9182083739045764 ,    (testing) 85.9375\n",
      "[epoch 210] loss: (training) 0.1419686377917365 , (testing) 0.15951931208837777 , accuracy: (training) 0.9191820837390458 ,    (testing) 81.640625\n",
      "[epoch 211] loss: (training) 0.14239927312491357 , (testing) 0.1533772696275264 , accuracy: (training) 0.9221032132424537 ,    (testing) 84.765625\n",
      "[epoch 212] loss: (training) 0.14218044347619407 , (testing) 0.1533418686594814 , accuracy: (training) 0.9191820837390458 ,    (testing) 84.765625\n",
      "[epoch 213] loss: (training) 0.14215866936075675 , (testing) 0.1548996608471498 , accuracy: (training) 0.9191820837390458 ,    (testing) 82.8125\n",
      "[epoch 214] loss: (training) 0.14171038192956625 , (testing) 0.15657832799479365 , accuracy: (training) 0.9211295034079844 ,    (testing) 82.03125\n",
      "[epoch 215] loss: (training) 0.14161904731111924 , (testing) 0.1529564141528681 , accuracy: (training) 0.9211295034079844 ,    (testing) 84.765625\n",
      "[epoch 216] loss: (training) 0.1441010440635496 , (testing) 0.15401597053278238 , accuracy: (training) 0.9191820837390458 ,    (testing) 83.984375\n",
      "[epoch 217] loss: (training) 0.14144384000808782 , (testing) 0.15440528036560863 , accuracy: (training) 0.9182083739045764 ,    (testing) 83.984375\n",
      "[epoch 218] loss: (training) 0.14164827041422082 , (testing) 0.1533105968264863 , accuracy: (training) 0.9201557935735151 ,    (testing) 84.765625\n",
      "[epoch 219] loss: (training) 0.1425078438832067 , (testing) 0.1524564161663875 , accuracy: (training) 0.9211295034079844 ,    (testing) 84.765625\n",
      "[epoch 220] loss: (training) 0.14120145401291992 , (testing) 0.15754564991220832 , accuracy: (training) 0.9250243427458618 ,    (testing) 82.03125\n",
      "[epoch 221] loss: (training) 0.1413613301787826 , (testing) 0.15836110664531589 , accuracy: (training) 0.9191820837390458 ,    (testing) 81.640625\n",
      "[epoch 222] loss: (training) 0.14132331741794552 , (testing) 0.15473541046958417 , accuracy: (training) 0.9211295034079844 ,    (testing) 83.59375\n",
      "[epoch 223] loss: (training) 0.14338440377811879 , (testing) 0.16267658467404544 , accuracy: (training) 0.9259980525803311 ,    (testing) 78.90625\n",
      "[epoch 224] loss: (training) 0.14113602149359109 , (testing) 0.1548694632947445 , accuracy: (training) 0.9221032132424537 ,    (testing) 83.203125\n",
      "[epoch 225] loss: (training) 0.14097687738166492 , (testing) 0.15219277481082827 , accuracy: (training) 0.9230769230769231 ,    (testing) 85.15625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 226] loss: (training) 0.14107920427827492 , (testing) 0.15669125400017947 , accuracy: (training) 0.9230769230769231 ,    (testing) 82.8125\n",
      "[epoch 227] loss: (training) 0.14088779615475439 , (testing) 0.15799647220410407 , accuracy: (training) 0.9211295034079844 ,    (testing) 82.8125\n",
      "[epoch 228] loss: (training) 0.14131904491182667 , (testing) 0.15450653480365872 , accuracy: (training) 0.9240506329113924 ,    (testing) 83.984375\n",
      "[epoch 229] loss: (training) 0.1417601254811208 , (testing) 0.1540542122675106 , accuracy: (training) 0.9259980525803311 ,    (testing) 84.375\n",
      "[epoch 230] loss: (training) 0.14073177364060205 , (testing) 0.15707676357124 , accuracy: (training) 0.9240506329113924 ,    (testing) 82.8125\n",
      "[epoch 231] loss: (training) 0.14060844091446914 , (testing) 0.15317558485548943 , accuracy: (training) 0.9259980525803311 ,    (testing) 84.375\n",
      "[epoch 232] loss: (training) 0.14064911184551881 , (testing) 0.1576570450561121 , accuracy: (training) 0.9230769230769231 ,    (testing) 81.640625\n",
      "[epoch 233] loss: (training) 0.14090193412741836 , (testing) 0.15343846986070275 , accuracy: (training) 0.9250243427458618 ,    (testing) 84.375\n",
      "[epoch 234] loss: (training) 0.14058817640685478 , (testing) 0.15561765409074724 , accuracy: (training) 0.9221032132424537 ,    (testing) 82.421875\n",
      "[epoch 235] loss: (training) 0.1402918500038347 , (testing) 0.15934771101456136 , accuracy: (training) 0.9240506329113924 ,    (testing) 81.25\n",
      "[epoch 236] loss: (training) 0.14048025938813494 , (testing) 0.1545806856593117 , accuracy: (training) 0.928919182083739 ,    (testing) 83.984375\n",
      "[epoch 237] loss: (training) 0.14079535114637734 , (testing) 0.15435330825857818 , accuracy: (training) 0.9259980525803311 ,    (testing) 83.984375\n",
      "[epoch 238] loss: (training) 0.14033613460404532 , (testing) 0.15750578313600272 , accuracy: (training) 0.9279454722492697 ,    (testing) 83.59375\n",
      "[epoch 239] loss: (training) 0.1402937362678313 , (testing) 0.15628656756598502 , accuracy: (training) 0.9230769230769231 ,    (testing) 82.8125\n",
      "[epoch 240] loss: (training) 0.14006338233039492 , (testing) 0.1519879272673279 , accuracy: (training) 0.9298928919182083 ,    (testing) 85.546875\n",
      "[epoch 241] loss: (training) 0.1404593933312145 , (testing) 0.15955504588782787 , accuracy: (training) 0.9259980525803311 ,    (testing) 82.03125\n",
      "[epoch 242] loss: (training) 0.14253126393254228 , (testing) 0.16013530176132917 , accuracy: (training) 0.9250243427458618 ,    (testing) 81.640625\n",
      "[epoch 243] loss: (training) 0.14060981833784184 , (testing) 0.15531368530355394 , accuracy: (training) 0.928919182083739 ,    (testing) 82.8125\n",
      "[epoch 244] loss: (training) 0.14076104296771386 , (testing) 0.15490425750613213 , accuracy: (training) 0.9250243427458618 ,    (testing) 83.984375\n",
      "[epoch 245] loss: (training) 0.13997644409030474 , (testing) 0.15541074762586504 , accuracy: (training) 0.9230769230769231 ,    (testing) 82.8125\n",
      "[epoch 246] loss: (training) 0.1405260997332915 , (testing) 0.16043264465406537 , accuracy: (training) 0.9221032132424537 ,    (testing) 81.25\n",
      "[epoch 247] loss: (training) 0.14235553463995165 , (testing) 0.15830087359063327 , accuracy: (training) 0.9279454722492697 ,    (testing) 82.8125\n",
      "[epoch 248] loss: (training) 0.1402228203818448 , (testing) 0.15708250051829964 , accuracy: (training) 0.9259980525803311 ,    (testing) 82.8125\n",
      "[epoch 249] loss: (training) 0.13974266355192927 , (testing) 0.15389340941328555 , accuracy: (training) 0.9279454722492697 ,    (testing) 84.375\n",
      "[epoch 250] loss: (training) 0.14006013167611134 , (testing) 0.1568520403234288 , accuracy: (training) 0.9250243427458618 ,    (testing) 82.8125\n",
      "[epoch 251] loss: (training) 0.1395493503388441 , (testing) 0.15638938068877906 , accuracy: (training) 0.9298928919182083 ,    (testing) 84.375\n",
      "[epoch 252] loss: (training) 0.139498371714174 , (testing) 0.16073482215870172 , accuracy: (training) 0.9318403115871471 ,    (testing) 80.078125\n",
      "[epoch 253] loss: (training) 0.13942843878350292 , (testing) 0.16253771784249693 , accuracy: (training) 0.9318403115871471 ,    (testing) 80.078125\n",
      "[epoch 254] loss: (training) 0.13941797211520063 , (testing) 0.1580570664955303 , accuracy: (training) 0.9279454722492697 ,    (testing) 82.03125\n",
      "[epoch 255] loss: (training) 0.13972605439038735 , (testing) 0.1541240243241191 , accuracy: (training) 0.9308666017526777 ,    (testing) 84.375\n",
      "[epoch 256] loss: (training) 0.13958524646865614 , (testing) 0.1614490372594446 , accuracy: (training) 0.9318403115871471 ,    (testing) 81.25\n",
      "[epoch 257] loss: (training) 0.1397002730355666 , (testing) 0.1593209661077708 , accuracy: (training) 0.9308666017526777 ,    (testing) 81.640625\n",
      "[epoch 258] loss: (training) 0.13992343517156106 , (testing) 0.15635668172035366 , accuracy: (training) 0.9328140214216164 ,    (testing) 83.203125\n",
      "[epoch 259] loss: (training) 0.13925095520862915 , (testing) 0.1573020953219384 , accuracy: (training) 0.9318403115871471 ,    (testing) 82.8125\n",
      "[epoch 260] loss: (training) 0.13928762709665807 , (testing) 0.15855467156507075 , accuracy: (training) 0.9298928919182083 ,    (testing) 82.8125\n",
      "[epoch 261] loss: (training) 0.13948796725713358 , (testing) 0.15777284430805594 , accuracy: (training) 0.9298928919182083 ,    (testing) 82.421875\n",
      "[epoch 262] loss: (training) 0.13992252702615698 , (testing) 0.1531197598669678 , accuracy: (training) 0.9318403115871471 ,    (testing) 84.765625\n",
      "[epoch 263] loss: (training) 0.1396790250513134 , (testing) 0.15699264174327254 , accuracy: (training) 0.9337877312560857 ,    (testing) 83.203125\n",
      "[epoch 264] loss: (training) 0.1394193058053305 , (testing) 0.15464484365656972 , accuracy: (training) 0.9328140214216164 ,    (testing) 85.15625\n",
      "[epoch 265] loss: (training) 0.13884620028172337 , (testing) 0.1564621926518157 , accuracy: (training) 0.9357351509250244 ,    (testing) 84.375\n",
      "[epoch 266] loss: (training) 0.13882038063859337 , (testing) 0.1607655839761719 , accuracy: (training) 0.9308666017526777 ,    (testing) 81.640625\n",
      "[epoch 267] loss: (training) 0.13880439118579016 , (testing) 0.15772899030707777 , accuracy: (training) 0.9308666017526777 ,    (testing) 82.8125\n",
      "[epoch 268] loss: (training) 0.13869451094994392 , (testing) 0.1569320160197094 , accuracy: (training) 0.934761441090555 ,    (testing) 83.984375\n",
      "[epoch 269] loss: (training) 0.13955720653802706 , (testing) 0.16065328347031027 , accuracy: (training) 0.9308666017526777 ,    (testing) 82.421875\n",
      "[epoch 270] loss: (training) 0.1384622844477321 , (testing) 0.15713071811478585 , accuracy: (training) 0.9337877312560857 ,    (testing) 83.203125\n",
      "[epoch 271] loss: (training) 0.1385564563109877 , (testing) 0.15079965349286795 , accuracy: (training) 0.9386562804284323 ,    (testing) 86.328125\n",
      "[epoch 272] loss: (training) 0.13852487161277682 , (testing) 0.15075980324763805 , accuracy: (training) 0.9386562804284323 ,    (testing) 86.328125\n",
      "[epoch 273] loss: (training) 0.13847247403263468 , (testing) 0.15922244440298527 , accuracy: (training) 0.9318403115871471 ,    (testing) 81.25\n",
      "[epoch 274] loss: (training) 0.13815862047544836 , (testing) 0.15995092445518821 , accuracy: (training) 0.934761441090555 ,    (testing) 80.859375\n",
      "[epoch 275] loss: (training) 0.1386795149658118 , (testing) 0.1581818099366501 , accuracy: (training) 0.9367088607594937 ,    (testing) 83.203125\n",
      "[epoch 276] loss: (training) 0.13828767872296918 , (testing) 0.15618390240706503 , accuracy: (training) 0.934761441090555 ,    (testing) 82.421875\n",
      "[epoch 277] loss: (training) 0.13851272266274872 , (testing) 0.16081592440605164 , accuracy: (training) 0.9357351509250244 ,    (testing) 80.46875\n",
      "[epoch 278] loss: (training) 0.13828520570945926 , (testing) 0.15620477101765573 , accuracy: (training) 0.934761441090555 ,    (testing) 83.59375\n",
      "[epoch 279] loss: (training) 0.1386355737439629 , (testing) 0.15586136223282665 , accuracy: (training) 0.937682570593963 ,    (testing) 83.59375\n",
      "[epoch 280] loss: (training) 0.13845114411371676 , (testing) 0.15644126036204398 , accuracy: (training) 0.9406037000973709 ,    (testing) 82.8125\n",
      "[epoch 281] loss: (training) 0.13818505985627946 , (testing) 0.16036893089767545 , accuracy: (training) 0.937682570593963 ,    (testing) 80.46875\n",
      "[epoch 282] loss: (training) 0.1390120819486149 , (testing) 0.15646259975619614 , accuracy: (training) 0.937682570593963 ,    (testing) 82.8125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 283] loss: (training) 0.13791591525657068 , (testing) 0.1596701688831672 , accuracy: (training) 0.9357351509250244 ,    (testing) 80.859375\n",
      "[epoch 284] loss: (training) 0.1378990654753063 , (testing) 0.15602177660912275 , accuracy: (training) 0.9406037000973709 ,    (testing) 82.8125\n",
      "[epoch 285] loss: (training) 0.13782505669329673 , (testing) 0.15542076516430825 , accuracy: (training) 0.9367088607594937 ,    (testing) 83.59375\n",
      "[epoch 286] loss: (training) 0.13764294034885596 , (testing) 0.14987868361640722 , accuracy: (training) 0.9425511197663097 ,    (testing) 85.9375\n",
      "[epoch 287] loss: (training) 0.13771741722137518 , (testing) 0.1602373415371403 , accuracy: (training) 0.937682570593963 ,    (testing) 80.46875\n",
      "[epoch 288] loss: (training) 0.13878288737654804 , (testing) 0.14896144182421267 , accuracy: (training) 0.937682570593963 ,    (testing) 86.328125\n",
      "[epoch 289] loss: (training) 0.1376785606985769 , (testing) 0.1541588215623051 , accuracy: (training) 0.9406037000973709 ,    (testing) 84.765625\n",
      "[epoch 290] loss: (training) 0.13779560643799452 , (testing) 0.1594392245169729 , accuracy: (training) 0.9386562804284323 ,    (testing) 82.421875\n",
      "[epoch 291] loss: (training) 0.13750543211477262 , (testing) 0.15615029237233102 , accuracy: (training) 0.937682570593963 ,    (testing) 82.421875\n",
      "[epoch 292] loss: (training) 0.1377924950929147 , (testing) 0.16311739722732455 , accuracy: (training) 0.9444985394352483 ,    (testing) 79.6875\n",
      "[epoch 293] loss: (training) 0.13735286258631707 , (testing) 0.15596608573105186 , accuracy: (training) 0.937682570593963 ,    (testing) 84.765625\n",
      "[epoch 294] loss: (training) 0.13735381446496392 , (testing) 0.15831095073372126 , accuracy: (training) 0.9386562804284323 ,    (testing) 83.203125\n"
     ]
    }
   ],
   "source": [
    "num_classes = 2\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# load neural network model\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "model = Linear(num_classes=num_classes)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Set the flag for using cuda\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "bCuda = 0\n",
    "\n",
    "if bCuda:\n",
    " \n",
    "    model.cuda()\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# optimization algorithm\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "optimizer   = optim.SGD(model.parameters(), lr=0.015, weight_decay=0.02)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=1, min_lr=2e-4, verbose=1)\n",
    "objective   = nn.CrossEntropyLoss()\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# function for training the model\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def train():\n",
    "\n",
    "    # print('train the model at given epoch')\n",
    "    accuracy_train = []\n",
    "    loss_train = []\n",
    "    correct = 0\n",
    "    correct_batch = 0\n",
    "\n",
    "    model.train()\n",
    "    for idx_batch, (data, target) in enumerate(trainloader):\n",
    "\n",
    "        if bCuda:\n",
    "        \n",
    "            data, target    = data.cuda(), target.cuda()\n",
    "\n",
    "        data, target    = Variable(data), Variable(target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output  = model(data)\n",
    "        loss    = objective(output, target)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_train_batch    = loss.item() / len(data)\n",
    "        loss_train.append(loss_train_batch)\n",
    "        pred        = output.data.max(1)[1]\n",
    "        correct     += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "        correct_batch = pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "        accuracy_train_batch = float(correct_batch) / len(data)\n",
    "        accuracy_train.append(accuracy_train_batch)\n",
    "        \n",
    "    loss_train_mean     = np.mean(loss_train)\n",
    "    loss_train_std      = np.std(loss_train)\n",
    "    accuracy_train_mean   = float(correct) / len(trainloader.dataset)  # mean accuracy\n",
    "\n",
    "    return {'loss_train_mean': loss_train_mean, 'loss_train_std': loss_train_std, 'accuracy_train_mean' : accuracy_train_mean}\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# function for testing the model\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def test():\n",
    "\n",
    "    # print('test the model at given epoch')\n",
    "\n",
    "    accuracy_test   = []\n",
    "    loss_test       = 0\n",
    "    correct         = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    for idx_batch, (data, target) in enumerate(valloader):\n",
    "\n",
    "        if bCuda:\n",
    "        \n",
    "            data, target    = data.cuda(), target.cuda()\n",
    "\n",
    "        data, target    = Variable(data), Variable(target)\n",
    "\n",
    "        output  = model(data)\n",
    "        loss    = objective(output, target)\n",
    "\n",
    "        loss_test   += loss.item()\n",
    "        pred        = output.data.max(1)[1]\n",
    "        correct     += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    loss_test       = loss_test / len(valloader.dataset)\n",
    "    accuracy_test   = 100. * float(correct) / len(valloader.dataset)\n",
    "\n",
    "    return {'loss_test': loss_test, 'accuracy_test': accuracy_test}\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# iteration for the epoch\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "loss_train_mean, loss_train_std, loss_test, accuracy_test = [], [], [], []\n",
    "loss_temp = 0;\n",
    "\n",
    "for e in range(3000):\n",
    "    \n",
    "    result_train    = train()\n",
    "    result_test     = test()\n",
    "    scheduler.step(result_test['loss_test'], e)\n",
    "\n",
    "    \n",
    "    loss_train_mean.append(result_train['loss_train_mean'])\n",
    "    loss_train_std.append(result_train['loss_train_std'])\n",
    "    loss_test.append(result_test['loss_test'])\n",
    "    accuracy_test.append(result_test['accuracy_test'])\n",
    "    \n",
    "    print(f\"[epoch {e}] loss: (training) {loss_train_mean[-1]} , (testing) {loss_test[-1]} , accuracy: (training) {result_train['accuracy_train_mean']} ,    (testing) {accuracy_test[-1]}\")\n",
    "    \n",
    "    if(abs(loss_temp - loss_train_mean[-1]) < 10e-7):\n",
    "        break;\n",
    "    loss_temp = loss_train_mean[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
