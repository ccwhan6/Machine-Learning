{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "class Linear(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=2):\n",
    "\n",
    "        super(Linear, self).__init__()\n",
    "\n",
    "        self.number_class   = num_classes\n",
    "\n",
    "        _size_image     = 100* 100\n",
    "        _num1           = 50\n",
    "        _num2           = 60\n",
    "        \n",
    "        self.fc1        = nn.Linear(_size_image, _num1, bias=True)\n",
    "        self.fc2        = nn.Linear(_num1, _num2, bias=True)\n",
    "        self.fc3        = nn.Linear(_num2, num_classes, bias=True)\n",
    "\n",
    "        self.fc_layer1  = nn.Sequential(self.fc1, nn.LeakyReLU(True))\n",
    "        self.fc_layer2  = nn.Sequential(self.fc2, nn.LeakyReLU(True))\n",
    "        self.fc_layer3  = nn.Sequential(self.fc3, nn.Sigmoid())\n",
    "        \n",
    "        self.classifier = nn.Sequential(self.fc_layer1, self.fc_layer2, self.fc_layer3)\n",
    "        \n",
    "        self._initialize_weight()        \n",
    "        \n",
    "    def _initialize_weight(self):\n",
    "\n",
    "        for name, m in self._modules.items():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                n = m.in_features\n",
    "                m.weight.data.uniform_(- 1.0 / math.sqrt(n), 1.0 / math.sqrt(n))\n",
    "\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime \n",
    "import csv\n",
    "import configparser\n",
    "import argparse\n",
    "import platform\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from random import shuffle\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# load dataset\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "transform = transforms.Compose([#transforms.Resize((256,256)),  \n",
    "                                transforms.Grayscale(),\t\t# the code transforms.Graysclae() is for changing the size [3,100,100] to [1, 100, 100] (notice : [channel, height, width] )\n",
    "                                transforms.ToTensor(),])\n",
    "\n",
    "\n",
    "#train_data_path = 'relative path of training data set'\n",
    "train_data_path = './horse-or-human/horse-or-human/train'\n",
    "trainset = torchvision.datasets.ImageFolder(root=train_data_path, transform=transform)\n",
    "# change the valuse of batch_size, num_workers for your program\n",
    "# if shuffle=True, the data reshuffled at every epoch \n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=3, shuffle=True, num_workers=1)  \n",
    "\n",
    "\n",
    "validation_data_path = './horse-or-human/horse-or-human/validation'\n",
    "valset = torchvision.datasets.ImageFolder(root=validation_data_path, transform=transform)\n",
    "# change the valuse of batch_size, num_workers for your program\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=3, shuffle=True, num_workers=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 0] loss: (training) 0.21917209799597867 , (testing) 0.18558936880435795 , accuracy: (training) 0.6105160662122687 ,    (testing) 74.609375\n",
      "[epoch 1] loss: (training) 0.19766214009160782 , (testing) 0.15269093750976026 , accuracy: (training) 0.7147030185004869 ,    (testing) 87.109375\n",
      "[epoch 2] loss: (training) 0.18334113506001098 , (testing) 0.15237864118535072 , accuracy: (training) 0.7546251217137293 ,    (testing) 86.71875\n",
      "[epoch 3] loss: (training) 0.17881103646303406 , (testing) 0.21603672951459885 , accuracy: (training) 0.7779941577409932 ,    (testing) 61.328125\n",
      "Epoch     4: reducing learning rate of group 0 to 1.5000e-03.\n",
      "[epoch 4] loss: (training) 0.17273381755002157 , (testing) 0.16047668259125203 , accuracy: (training) 0.7964946445959105 ,    (testing) 82.03125\n",
      "[epoch 5] loss: (training) 0.16253255882578294 , (testing) 0.15092049597296864 , accuracy: (training) 0.8393378773125608 ,    (testing) 85.15625\n",
      "[epoch 6] loss: (training) 0.15946532616462375 , (testing) 0.16279690864030272 , accuracy: (training) 0.8558909444985394 ,    (testing) 81.25\n",
      "Epoch     7: reducing learning rate of group 0 to 2.0000e-04.\n",
      "[epoch 7] loss: (training) 0.15892001974918635 , (testing) 0.15671979100443423 , accuracy: (training) 0.857838364167478 ,    (testing) 83.203125\n",
      "[epoch 8] loss: (training) 0.15776478198689087 , (testing) 0.15544330596458167 , accuracy: (training) 0.8597857838364168 ,    (testing) 84.765625\n",
      "[epoch 9] loss: (training) 0.1587766730982314 , (testing) 0.14961738232523203 , accuracy: (training) 0.8627069133398247 ,    (testing) 85.9375\n",
      "[epoch 10] loss: (training) 0.1575559190573104 , (testing) 0.14941134909167886 , accuracy: (training) 0.8597857838364168 ,    (testing) 86.328125\n",
      "[epoch 11] loss: (training) 0.15788093096313255 , (testing) 0.15191346919164062 , accuracy: (training) 0.8636806231742941 ,    (testing) 84.765625\n",
      "[epoch 12] loss: (training) 0.15853651193766136 , (testing) 0.1513575918506831 , accuracy: (training) 0.8636806231742941 ,    (testing) 84.765625\n",
      "[epoch 13] loss: (training) 0.15719575935248847 , (testing) 0.15067062026355416 , accuracy: (training) 0.8636806231742941 ,    (testing) 85.15625\n",
      "[epoch 14] loss: (training) 0.15809270707696707 , (testing) 0.15165690646972507 , accuracy: (training) 0.8656280428432327 ,    (testing) 84.765625\n",
      "[epoch 15] loss: (training) 0.15688892205556235 , (testing) 0.15117237088270485 , accuracy: (training) 0.8627069133398247 ,    (testing) 84.765625\n",
      "[epoch 16] loss: (training) 0.15821200895935036 , (testing) 0.15475645079277456 , accuracy: (training) 0.8636806231742941 ,    (testing) 84.765625\n",
      "[epoch 17] loss: (training) 0.15681283817462718 , (testing) 0.14969432610087097 , accuracy: (training) 0.8617332035053554 ,    (testing) 85.9375\n",
      "[epoch 18] loss: (training) 0.15713651123501007 , (testing) 0.15079731936566532 , accuracy: (training) 0.8646543330087634 ,    (testing) 84.765625\n",
      "[epoch 19] loss: (training) 0.15681506182176608 , (testing) 0.15287458209786564 , accuracy: (training) 0.8656280428432327 ,    (testing) 84.765625\n",
      "[epoch 20] loss: (training) 0.15627837818264384 , (testing) 0.14988716575317085 , accuracy: (training) 0.8685491723466408 ,    (testing) 85.9375\n",
      "[epoch 21] loss: (training) 0.15622810748622065 , (testing) 0.14972233842127025 , accuracy: (training) 0.8646543330087634 ,    (testing) 85.9375\n",
      "[epoch 22] loss: (training) 0.15638809220320513 , (testing) 0.14969893114175647 , accuracy: (training) 0.866601752677702 ,    (testing) 85.9375\n",
      "[epoch 23] loss: (training) 0.15694690949715262 , (testing) 0.1532060692552477 , accuracy: (training) 0.8656280428432327 ,    (testing) 85.15625\n",
      "[epoch 24] loss: (training) 0.1559986827208998 , (testing) 0.15142773371189833 , accuracy: (training) 0.8646543330087634 ,    (testing) 85.15625\n",
      "[epoch 25] loss: (training) 0.1574785726468927 , (testing) 0.15105425426736474 , accuracy: (training) 0.866601752677702 ,    (testing) 84.765625\n",
      "[epoch 26] loss: (training) 0.15576091011944504 , (testing) 0.1522216701414436 , accuracy: (training) 0.8695228821811101 ,    (testing) 84.765625\n",
      "[epoch 27] loss: (training) 0.15818471785189459 , (testing) 0.15263049700297415 , accuracy: (training) 0.8695228821811101 ,    (testing) 84.765625\n",
      "[epoch 28] loss: (training) 0.15608552576154036 , (testing) 0.15206379105802625 , accuracy: (training) 0.8714703018500487 ,    (testing) 84.765625\n",
      "[epoch 29] loss: (training) 0.15624688193564049 , (testing) 0.15157445869408548 , accuracy: (training) 0.8675754625121713 ,    (testing) 85.15625\n",
      "[epoch 30] loss: (training) 0.15531232118954116 , (testing) 0.14950114442035556 , accuracy: (training) 0.8704965920155794 ,    (testing) 85.9375\n",
      "[epoch 31] loss: (training) 0.15547281920736108 , (testing) 0.1489185009850189 , accuracy: (training) 0.875365141187926 ,    (testing) 86.71875\n",
      "[epoch 32] loss: (training) 0.15515843725992243 , (testing) 0.1531346543924883 , accuracy: (training) 0.8734177215189873 ,    (testing) 84.765625\n",
      "[epoch 33] loss: (training) 0.15509668285112221 , (testing) 0.15336753451265395 , accuracy: (training) 0.8734177215189873 ,    (testing) 84.375\n",
      "[epoch 34] loss: (training) 0.15750568705467025 , (testing) 0.15049399994313717 , accuracy: (training) 0.8773125608568647 ,    (testing) 85.15625\n",
      "[epoch 35] loss: (training) 0.15537001405443465 , (testing) 0.15242597472388297 , accuracy: (training) 0.8734177215189873 ,    (testing) 84.765625\n",
      "[epoch 36] loss: (training) 0.15482915499119995 , (testing) 0.15156537492293864 , accuracy: (training) 0.878286270691334 ,    (testing) 84.765625\n",
      "[epoch 37] loss: (training) 0.1549842781065968 , (testing) 0.1524070028681308 , accuracy: (training) 0.875365141187926 ,    (testing) 84.765625\n",
      "[epoch 38] loss: (training) 0.15503291210813122 , (testing) 0.15228866727557033 , accuracy: (training) 0.878286270691334 ,    (testing) 84.765625\n",
      "[epoch 39] loss: (training) 0.15525517400546024 , (testing) 0.1513491147197783 , accuracy: (training) 0.878286270691334 ,    (testing) 84.765625\n",
      "[epoch 40] loss: (training) 0.15476318521912058 , (testing) 0.15174832672346383 , accuracy: (training) 0.8763388510223953 ,    (testing) 85.15625\n",
      "[epoch 41] loss: (training) 0.15424730287696461 , (testing) 0.15318246942479163 , accuracy: (training) 0.875365141187926 ,    (testing) 84.375\n",
      "[epoch 42] loss: (training) 0.15419419033070927 , (testing) 0.15335652930662036 , accuracy: (training) 0.8763388510223953 ,    (testing) 84.375\n",
      "[epoch 43] loss: (training) 0.15413371730592207 , (testing) 0.15301645186264068 , accuracy: (training) 0.8773125608568647 ,    (testing) 83.984375\n",
      "[epoch 44] loss: (training) 0.15395495179674948 , (testing) 0.1499586704885587 , accuracy: (training) 0.8792599805258033 ,    (testing) 85.546875\n",
      "[epoch 45] loss: (training) 0.15390782523085703 , (testing) 0.15513150987681001 , accuracy: (training) 0.875365141187926 ,    (testing) 82.8125\n",
      "[epoch 46] loss: (training) 0.15397195806192818 , (testing) 0.15359433949925005 , accuracy: (training) 0.8802336903602727 ,    (testing) 84.375\n",
      "[epoch 47] loss: (training) 0.15425058889435378 , (testing) 0.15303647879045457 , accuracy: (training) 0.8743914313534566 ,    (testing) 83.984375\n",
      "[epoch 48] loss: (training) 0.15401900808016458 , (testing) 0.15092316712252796 , accuracy: (training) 0.878286270691334 ,    (testing) 85.15625\n",
      "[epoch 49] loss: (training) 0.15380974465834504 , (testing) 0.1501660948852077 , accuracy: (training) 0.8821811100292113 ,    (testing) 85.15625\n",
      "[epoch 50] loss: (training) 0.15403428103184677 , (testing) 0.1536873906152323 , accuracy: (training) 0.881207400194742 ,    (testing) 83.984375\n",
      "[epoch 51] loss: (training) 0.1536635123084655 , (testing) 0.14927921735215932 , accuracy: (training) 0.8821811100292113 ,    (testing) 85.9375\n",
      "[epoch 52] loss: (training) 0.15331141655021088 , (testing) 0.15482918545603752 , accuracy: (training) 0.8802336903602727 ,    (testing) 83.984375\n",
      "[epoch 53] loss: (training) 0.15351115443732 , (testing) 0.14976315945386887 , accuracy: (training) 0.8851022395326192 ,    (testing) 85.9375\n",
      "[epoch 54] loss: (training) 0.153466911803645 , (testing) 0.15619472705293447 , accuracy: (training) 0.887049659201558 ,    (testing) 82.03125\n",
      "[epoch 55] loss: (training) 0.15358956521639439 , (testing) 0.150971133611165 , accuracy: (training) 0.8821811100292113 ,    (testing) 85.15625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 56] loss: (training) 0.15287885906860826 , (testing) 0.151406251010485 , accuracy: (training) 0.8851022395326192 ,    (testing) 84.765625\n",
      "[epoch 57] loss: (training) 0.1528524754693835 , (testing) 0.15139210980851203 , accuracy: (training) 0.8841285296981499 ,    (testing) 84.765625\n",
      "[epoch 58] loss: (training) 0.15276110068007043 , (testing) 0.15629911608994007 , accuracy: (training) 0.8831548198636806 ,    (testing) 82.03125\n",
      "[epoch 59] loss: (training) 0.15275961285198164 , (testing) 0.15585563087370247 , accuracy: (training) 0.8821811100292113 ,    (testing) 83.203125\n",
      "[epoch 60] loss: (training) 0.1526060685935359 , (testing) 0.15354278474114835 , accuracy: (training) 0.8860759493670886 ,    (testing) 83.984375\n",
      "[epoch 61] loss: (training) 0.1523941448003604 , (testing) 0.14839531620964408 , accuracy: (training) 0.8841285296981499 ,    (testing) 87.109375\n",
      "[epoch 62] loss: (training) 0.152549750835022 , (testing) 0.15238131512887776 , accuracy: (training) 0.8831548198636806 ,    (testing) 84.375\n",
      "[epoch 63] loss: (training) 0.15329859428201867 , (testing) 0.15321364463306963 , accuracy: (training) 0.8860759493670886 ,    (testing) 83.984375\n",
      "[epoch 64] loss: (training) 0.1522772973086558 , (testing) 0.15328267682343721 , accuracy: (training) 0.8860759493670886 ,    (testing) 83.984375\n",
      "[epoch 65] loss: (training) 0.15212292177104855 , (testing) 0.15316934220027179 , accuracy: (training) 0.8821811100292113 ,    (testing) 83.59375\n",
      "[epoch 66] loss: (training) 0.15207847173753816 , (testing) 0.14986502390820533 , accuracy: (training) 0.8841285296981499 ,    (testing) 85.9375\n",
      "[epoch 67] loss: (training) 0.15236809991654898 , (testing) 0.15126825799234211 , accuracy: (training) 0.8841285296981499 ,    (testing) 84.765625\n",
      "[epoch 68] loss: (training) 0.15203551277590677 , (testing) 0.151333317742683 , accuracy: (training) 0.881207400194742 ,    (testing) 84.765625\n",
      "[epoch 69] loss: (training) 0.15181016974129413 , (testing) 0.1551622322294861 , accuracy: (training) 0.887049659201558 ,    (testing) 83.59375\n",
      "[epoch 70] loss: (training) 0.15169753662814667 , (testing) 0.15243513986933976 , accuracy: (training) 0.8899707887049659 ,    (testing) 83.984375\n",
      "[epoch 71] loss: (training) 0.1516535890924919 , (testing) 0.1523264654679224 , accuracy: (training) 0.8860759493670886 ,    (testing) 84.765625\n",
      "[epoch 72] loss: (training) 0.15169528989796505 , (testing) 0.15378568856976926 , accuracy: (training) 0.8851022395326192 ,    (testing) 83.59375\n",
      "[epoch 73] loss: (training) 0.15215802042083446 , (testing) 0.14953318273182958 , accuracy: (training) 0.887049659201558 ,    (testing) 86.328125\n",
      "[epoch 74] loss: (training) 0.151403845138522 , (testing) 0.1529790562344715 , accuracy: (training) 0.8841285296981499 ,    (testing) 83.59375\n",
      "[epoch 75] loss: (training) 0.1528427102996726 , (testing) 0.15078754350543022 , accuracy: (training) 0.8851022395326192 ,    (testing) 85.15625\n",
      "[epoch 76] loss: (training) 0.15142545735407384 , (testing) 0.1508539585629478 , accuracy: (training) 0.8851022395326192 ,    (testing) 84.765625\n",
      "[epoch 77] loss: (training) 0.1519889920457575 , (testing) 0.15308300266042352 , accuracy: (training) 0.8860759493670886 ,    (testing) 83.59375\n",
      "[epoch 78] loss: (training) 0.15105355032099696 , (testing) 0.15095288248267025 , accuracy: (training) 0.8880233690360273 ,    (testing) 85.15625\n",
      "[epoch 79] loss: (training) 0.15148599815090613 , (testing) 0.15334537695161998 , accuracy: (training) 0.887049659201558 ,    (testing) 83.59375\n",
      "[epoch 80] loss: (training) 0.15109798772689553 , (testing) 0.1523173482855782 , accuracy: (training) 0.8860759493670886 ,    (testing) 83.59375\n",
      "[epoch 81] loss: (training) 0.15154610703128188 , (testing) 0.15599621238652617 , accuracy: (training) 0.887049659201558 ,    (testing) 81.640625\n",
      "[epoch 82] loss: (training) 0.15080109264690741 , (testing) 0.15254632208961993 , accuracy: (training) 0.887049659201558 ,    (testing) 83.59375\n",
      "[epoch 83] loss: (training) 0.15102050029849173 , (testing) 0.1553464042954147 , accuracy: (training) 0.887049659201558 ,    (testing) 83.59375\n",
      "[epoch 84] loss: (training) 0.150758293934304 , (testing) 0.14992742286995053 , accuracy: (training) 0.887049659201558 ,    (testing) 85.9375\n",
      "[epoch 85] loss: (training) 0.15072857059241498 , (testing) 0.1532510439865291 , accuracy: (training) 0.8889970788704966 ,    (testing) 83.203125\n",
      "[epoch 86] loss: (training) 0.15032834970221226 , (testing) 0.14972815779037774 , accuracy: (training) 0.8919182083739046 ,    (testing) 85.546875\n",
      "[epoch 87] loss: (training) 0.15040171227487578 , (testing) 0.15405557258054614 , accuracy: (training) 0.8899707887049659 ,    (testing) 83.203125\n",
      "[epoch 88] loss: (training) 0.1502949201272922 , (testing) 0.15461259754374623 , accuracy: (training) 0.8880233690360273 ,    (testing) 83.203125\n",
      "[epoch 89] loss: (training) 0.1503457463227857 , (testing) 0.15618327667471021 , accuracy: (training) 0.8880233690360273 ,    (testing) 81.640625\n",
      "[epoch 90] loss: (training) 0.15086773304364656 , (testing) 0.1537315013119951 , accuracy: (training) 0.8919182083739046 ,    (testing) 83.59375\n",
      "[epoch 91] loss: (training) 0.1500590504432211 , (testing) 0.15347810578532517 , accuracy: (training) 0.8909444985394352 ,    (testing) 83.203125\n",
      "[epoch 92] loss: (training) 0.1497429427125132 , (testing) 0.15092790790367872 , accuracy: (training) 0.8919182083739046 ,    (testing) 85.15625\n",
      "[epoch 93] loss: (training) 0.1522391844537214 , (testing) 0.15365031186956912 , accuracy: (training) 0.887049659201558 ,    (testing) 83.59375\n",
      "[epoch 94] loss: (training) 0.1498172544992816 , (testing) 0.15500264067668468 , accuracy: (training) 0.8899707887049659 ,    (testing) 82.03125\n",
      "[epoch 95] loss: (training) 0.14972572177793358 , (testing) 0.15145742264576256 , accuracy: (training) 0.8919182083739046 ,    (testing) 84.375\n",
      "[epoch 96] loss: (training) 0.14987633782063328 , (testing) 0.1535585824167356 , accuracy: (training) 0.8889970788704966 ,    (testing) 83.59375\n",
      "[epoch 97] loss: (training) 0.1496367995836297 , (testing) 0.15659460285678506 , accuracy: (training) 0.8919182083739046 ,    (testing) 81.640625\n",
      "[epoch 98] loss: (training) 0.1501366259463211 , (testing) 0.1542530582519248 , accuracy: (training) 0.8919182083739046 ,    (testing) 83.984375\n",
      "[epoch 99] loss: (training) 0.1518961472692017 , (testing) 0.15540877217426896 , accuracy: (training) 0.8928919182083739 ,    (testing) 82.03125\n",
      "[epoch 100] loss: (training) 0.14926770532212288 , (testing) 0.1517608700087294 , accuracy: (training) 0.8938656280428432 ,    (testing) 84.375\n",
      "[epoch 101] loss: (training) 0.1491230582878124 , (testing) 0.1520450602984056 , accuracy: (training) 0.8928919182083739 ,    (testing) 85.9375\n",
      "[epoch 102] loss: (training) 0.1496000822825381 , (testing) 0.1513693886809051 , accuracy: (training) 0.8958130477117819 ,    (testing) 84.375\n",
      "[epoch 103] loss: (training) 0.14899424717655682 , (testing) 0.1531859749229625 , accuracy: (training) 0.8967867575462513 ,    (testing) 83.203125\n",
      "[epoch 104] loss: (training) 0.1493578907120448 , (testing) 0.14986764220520854 , accuracy: (training) 0.8948393378773125 ,    (testing) 85.9375\n",
      "[epoch 105] loss: (training) 0.14941415399226085 , (testing) 0.15116098592989147 , accuracy: (training) 0.8958130477117819 ,    (testing) 84.765625\n",
      "[epoch 106] loss: (training) 0.1489680282576091 , (testing) 0.15378142660483718 , accuracy: (training) 0.8919182083739046 ,    (testing) 83.984375\n",
      "[epoch 107] loss: (training) 0.14951582801816993 , (testing) 0.15748847101349384 , accuracy: (training) 0.8948393378773125 ,    (testing) 81.640625\n",
      "[epoch 108] loss: (training) 0.148922312450826 , (testing) 0.15477823524270207 , accuracy: (training) 0.8958130477117819 ,    (testing) 82.03125\n",
      "[epoch 109] loss: (training) 0.1490290508152097 , (testing) 0.15033911645878106 , accuracy: (training) 0.8928919182083739 ,    (testing) 85.9375\n",
      "[epoch 110] loss: (training) 0.14868170570354072 , (testing) 0.15289384010247886 , accuracy: (training) 0.8967867575462513 ,    (testing) 83.59375\n",
      "[epoch 111] loss: (training) 0.14865749040428472 , (testing) 0.15139015100430697 , accuracy: (training) 0.8967867575462513 ,    (testing) 84.765625\n",
      "[epoch 112] loss: (training) 0.14939930997390674 , (testing) 0.15571767394430935 , accuracy: (training) 0.8948393378773125 ,    (testing) 82.421875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 113] loss: (training) 0.148459455622876 , (testing) 0.15146819490473717 , accuracy: (training) 0.8928919182083739 ,    (testing) 85.15625\n",
      "[epoch 114] loss: (training) 0.14873855776063902 , (testing) 0.15126525214873254 , accuracy: (training) 0.8958130477117819 ,    (testing) 85.15625\n",
      "[epoch 115] loss: (training) 0.1487805593118028 , (testing) 0.15323730546515435 , accuracy: (training) 0.8977604673807206 ,    (testing) 82.421875\n",
      "[epoch 116] loss: (training) 0.14820488053577635 , (testing) 0.15361764922272414 , accuracy: (training) 0.8958130477117819 ,    (testing) 82.421875\n",
      "[epoch 117] loss: (training) 0.14788141212379968 , (testing) 0.15594801132101566 , accuracy: (training) 0.8977604673807206 ,    (testing) 82.03125\n",
      "[epoch 118] loss: (training) 0.1482943096012601 , (testing) 0.1497703093336895 , accuracy: (training) 0.9016553067185978 ,    (testing) 86.71875\n",
      "[epoch 119] loss: (training) 0.1479451055371495 , (testing) 0.15270048682577908 , accuracy: (training) 0.8948393378773125 ,    (testing) 83.984375\n",
      "[epoch 120] loss: (training) 0.14901537997729578 , (testing) 0.15372814307920635 , accuracy: (training) 0.8987341772151899 ,    (testing) 84.765625\n",
      "[epoch 121] loss: (training) 0.14779005798468667 , (testing) 0.1537098140688613 , accuracy: (training) 0.8958130477117819 ,    (testing) 82.421875\n",
      "[epoch 122] loss: (training) 0.1476579822013399 , (testing) 0.1554936917964369 , accuracy: (training) 0.8977604673807206 ,    (testing) 82.03125\n",
      "[epoch 123] loss: (training) 0.14834422159820534 , (testing) 0.1522265411913395 , accuracy: (training) 0.9006815968841285 ,    (testing) 84.375\n",
      "[epoch 124] loss: (training) 0.14746166935119961 , (testing) 0.15288942446932197 , accuracy: (training) 0.9016553067185978 ,    (testing) 84.375\n",
      "[epoch 125] loss: (training) 0.1474566917261878 , (testing) 0.1533892813604325 , accuracy: (training) 0.9006815968841285 ,    (testing) 82.421875\n",
      "[epoch 126] loss: (training) 0.14754869430475262 , (testing) 0.1557975832838565 , accuracy: (training) 0.9016553067185978 ,    (testing) 82.03125\n",
      "[epoch 127] loss: (training) 0.14751336508520144 , (testing) 0.15318027138710022 , accuracy: (training) 0.8997078870496592 ,    (testing) 83.203125\n",
      "[epoch 128] loss: (training) 0.14744970723769407 , (testing) 0.15412799175828695 , accuracy: (training) 0.8987341772151899 ,    (testing) 82.8125\n",
      "[epoch 129] loss: (training) 0.14705169641125884 , (testing) 0.15022487950045615 , accuracy: (training) 0.9006815968841285 ,    (testing) 86.328125\n",
      "[epoch 130] loss: (training) 0.14729251191961293 , (testing) 0.15254662686493248 , accuracy: (training) 0.9026290165530672 ,    (testing) 84.375\n",
      "[epoch 131] loss: (training) 0.14701327354266183 , (testing) 0.15243145416025072 , accuracy: (training) 0.9036027263875365 ,    (testing) 85.15625\n",
      "[epoch 132] loss: (training) 0.14686487153158012 , (testing) 0.15520570485386997 , accuracy: (training) 0.9036027263875365 ,    (testing) 82.03125\n",
      "[epoch 133] loss: (training) 0.14715183809385124 , (testing) 0.15214373427443206 , accuracy: (training) 0.9036027263875365 ,    (testing) 84.765625\n",
      "[epoch 134] loss: (training) 0.14675897058638934 , (testing) 0.15879186487291008 , accuracy: (training) 0.9036027263875365 ,    (testing) 81.25\n",
      "[epoch 135] loss: (training) 0.14719736567391598 , (testing) 0.15313971869181842 , accuracy: (training) 0.9036027263875365 ,    (testing) 83.59375\n",
      "[epoch 136] loss: (training) 0.14679705749100222 , (testing) 0.15131588513031602 , accuracy: (training) 0.9074975657254138 ,    (testing) 84.765625\n",
      "[epoch 137] loss: (training) 0.14722095752828204 , (testing) 0.15189260768238455 , accuracy: (training) 0.9074975657254138 ,    (testing) 84.765625\n",
      "[epoch 138] loss: (training) 0.14712685792624547 , (testing) 0.15608648606576025 , accuracy: (training) 0.9065238558909445 ,    (testing) 82.03125\n",
      "[epoch 139] loss: (training) 0.14650011630285356 , (testing) 0.1531349099241197 , accuracy: (training) 0.9065238558909445 ,    (testing) 83.59375\n",
      "[epoch 140] loss: (training) 0.14639784930051242 , (testing) 0.15100740711204708 , accuracy: (training) 0.9065238558909445 ,    (testing) 85.15625\n",
      "[epoch 141] loss: (training) 0.1462663716778695 , (testing) 0.15379465837031603 , accuracy: (training) 0.9074975657254138 ,    (testing) 85.15625\n",
      "[epoch 142] loss: (training) 0.14635833588123787 , (testing) 0.1511520268395543 , accuracy: (training) 0.9055501460564752 ,    (testing) 85.15625\n",
      "[epoch 143] loss: (training) 0.14645183500557762 , (testing) 0.15891002188436687 , accuracy: (training) 0.9084712755598832 ,    (testing) 80.46875\n",
      "[epoch 144] loss: (training) 0.1460777480006797 , (testing) 0.15824183472432196 , accuracy: (training) 0.9055501460564752 ,    (testing) 80.46875\n",
      "[epoch 145] loss: (training) 0.14602904034773045 , (testing) 0.15682108351029456 , accuracy: (training) 0.9094449853943525 ,    (testing) 81.640625\n",
      "[epoch 146] loss: (training) 0.14597454226862702 , (testing) 0.15233209042344242 , accuracy: (training) 0.9065238558909445 ,    (testing) 84.375\n",
      "[epoch 147] loss: (training) 0.14588300297281137 , (testing) 0.15185765305068344 , accuracy: (training) 0.9055501460564752 ,    (testing) 85.15625\n",
      "[epoch 148] loss: (training) 0.1458486408082111 , (testing) 0.15366263419855386 , accuracy: (training) 0.9074975657254138 ,    (testing) 83.203125\n",
      "[epoch 149] loss: (training) 0.1461309238008438 , (testing) 0.15521813288796693 , accuracy: (training) 0.9084712755598832 ,    (testing) 83.203125\n",
      "[epoch 150] loss: (training) 0.1463159840586582 , (testing) 0.15467739605810493 , accuracy: (training) 0.9074975657254138 ,    (testing) 82.8125\n",
      "[epoch 151] loss: (training) 0.14564126973249475 , (testing) 0.15472100349143147 , accuracy: (training) 0.9094449853943525 ,    (testing) 84.375\n",
      "[epoch 152] loss: (training) 0.14582665468791484 , (testing) 0.15182189154438674 , accuracy: (training) 0.9094449853943525 ,    (testing) 85.15625\n",
      "[epoch 153] loss: (training) 0.145417478648752 , (testing) 0.15091167017817497 , accuracy: (training) 0.9104186952288218 ,    (testing) 85.546875\n",
      "[epoch 154] loss: (training) 0.14550836518971635 , (testing) 0.15455248532816768 , accuracy: (training) 0.9084712755598832 ,    (testing) 84.765625\n",
      "[epoch 155] loss: (training) 0.14559946208468216 , (testing) 0.15316800132859498 , accuracy: (training) 0.9094449853943525 ,    (testing) 84.375\n",
      "[epoch 156] loss: (training) 0.14677246660718188 , (testing) 0.15768401662353426 , accuracy: (training) 0.9104186952288218 ,    (testing) 80.46875\n",
      "[epoch 157] loss: (training) 0.14518460214311804 , (testing) 0.1497104992158711 , accuracy: (training) 0.9104186952288218 ,    (testing) 87.5\n",
      "[epoch 158] loss: (training) 0.14512307419142062 , (testing) 0.15761279047001153 , accuracy: (training) 0.9133398247322297 ,    (testing) 82.03125\n",
      "[epoch 159] loss: (training) 0.1454035083974184 , (testing) 0.1536049909191206 , accuracy: (training) 0.9074975657254138 ,    (testing) 84.375\n",
      "[epoch 160] loss: (training) 0.14510309922104328 , (testing) 0.15410961210727692 , accuracy: (training) 0.9113924050632911 ,    (testing) 84.375\n",
      "[epoch 161] loss: (training) 0.1449220780033412 , (testing) 0.15569184871856123 , accuracy: (training) 0.9094449853943525 ,    (testing) 82.03125\n",
      "[epoch 162] loss: (training) 0.14577980303324117 , (testing) 0.15345798525959253 , accuracy: (training) 0.9123661148977604 ,    (testing) 83.984375\n",
      "[epoch 163] loss: (training) 0.14470375852751663 , (testing) 0.1533227419713512 , accuracy: (training) 0.9123661148977604 ,    (testing) 86.328125\n",
      "[epoch 164] loss: (training) 0.14480257138566444 , (testing) 0.1550976608414203 , accuracy: (training) 0.9104186952288218 ,    (testing) 83.984375\n",
      "[epoch 165] loss: (training) 0.14478232251775275 , (testing) 0.15753826522268355 , accuracy: (training) 0.9123661148977604 ,    (testing) 81.640625\n",
      "[epoch 166] loss: (training) 0.14463632832579063 , (testing) 0.15531585027929395 , accuracy: (training) 0.9113924050632911 ,    (testing) 82.03125\n",
      "[epoch 167] loss: (training) 0.14457933539551826 , (testing) 0.15359401633031666 , accuracy: (training) 0.9143135345666992 ,    (testing) 83.984375\n",
      "[epoch 168] loss: (training) 0.14452431318363712 , (testing) 0.1556588839739561 , accuracy: (training) 0.9152872444011685 ,    (testing) 82.03125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 169] loss: (training) 0.144454124283165 , (testing) 0.15786303742788732 , accuracy: (training) 0.9133398247322297 ,    (testing) 80.46875\n",
      "[epoch 170] loss: (training) 0.1444171902273788 , (testing) 0.15334802167490125 , accuracy: (training) 0.9123661148977604 ,    (testing) 84.375\n",
      "[epoch 171] loss: (training) 0.14474016653900593 , (testing) 0.15344935143366456 , accuracy: (training) 0.9104186952288218 ,    (testing) 84.375\n",
      "[epoch 172] loss: (training) 0.1441805732841047 , (testing) 0.15576600166969 , accuracy: (training) 0.9104186952288218 ,    (testing) 82.8125\n",
      "[epoch 173] loss: (training) 0.14414947619706941 , (testing) 0.1524863630766049 , accuracy: (training) 0.9152872444011685 ,    (testing) 85.15625\n",
      "[epoch 174] loss: (training) 0.14425070840137694 , (testing) 0.15519708779174834 , accuracy: (training) 0.9133398247322297 ,    (testing) 82.8125\n",
      "[epoch 175] loss: (training) 0.14413640265098696 , (testing) 0.15280309552326798 , accuracy: (training) 0.9133398247322297 ,    (testing) 85.546875\n",
      "[epoch 176] loss: (training) 0.14389380340557636 , (testing) 0.15367148048244417 , accuracy: (training) 0.9104186952288218 ,    (testing) 85.15625\n",
      "[epoch 177] loss: (training) 0.14402970752748503 , (testing) 0.15727410453837365 , accuracy: (training) 0.9172346640701071 ,    (testing) 81.25\n",
      "[epoch 178] loss: (training) 0.1438661998226529 , (testing) 0.15936188050545752 , accuracy: (training) 0.9143135345666992 ,    (testing) 81.25\n",
      "[epoch 179] loss: (training) 0.14389250183476188 , (testing) 0.15870109491515905 , accuracy: (training) 0.9143135345666992 ,    (testing) 80.46875\n",
      "[epoch 180] loss: (training) 0.1461228717867904 , (testing) 0.1560815202537924 , accuracy: (training) 0.9162609542356378 ,    (testing) 81.640625\n",
      "[epoch 181] loss: (training) 0.14434177204749327 , (testing) 0.15936721256002784 , accuracy: (training) 0.9162609542356378 ,    (testing) 80.46875\n",
      "[epoch 182] loss: (training) 0.14453040901843034 , (testing) 0.16160104097798467 , accuracy: (training) 0.9172346640701071 ,    (testing) 80.46875\n",
      "[epoch 183] loss: (training) 0.14361849566242785 , (testing) 0.15812763152644038 , accuracy: (training) 0.9172346640701071 ,    (testing) 80.46875\n",
      "[epoch 184] loss: (training) 0.14355239642836493 , (testing) 0.15454341983422637 , accuracy: (training) 0.9152872444011685 ,    (testing) 83.203125\n",
      "[epoch 185] loss: (training) 0.1433942046295218 , (testing) 0.15800479368772358 , accuracy: (training) 0.9133398247322297 ,    (testing) 81.25\n",
      "[epoch 186] loss: (training) 0.1433429393638559 , (testing) 0.1610867689596489 , accuracy: (training) 0.9143135345666992 ,    (testing) 79.296875\n",
      "[epoch 187] loss: (training) 0.1438315338713087 , (testing) 0.15368108602706343 , accuracy: (training) 0.9152872444011685 ,    (testing) 83.984375\n",
      "[epoch 188] loss: (training) 0.14371092685573417 , (testing) 0.15273975068703294 , accuracy: (training) 0.9162609542356378 ,    (testing) 85.15625\n",
      "[epoch 189] loss: (training) 0.1441519351058845 , (testing) 0.16363377845846117 , accuracy: (training) 0.9143135345666992 ,    (testing) 78.90625\n",
      "[epoch 190] loss: (training) 0.1432238999678164 , (testing) 0.15452413423918188 , accuracy: (training) 0.9152872444011685 ,    (testing) 83.203125\n",
      "[epoch 191] loss: (training) 0.14274881752633262 , (testing) 0.16043859452474862 , accuracy: (training) 0.9191820837390458 ,    (testing) 80.46875\n",
      "[epoch 192] loss: (training) 0.1429500686415662 , (testing) 0.15148743521422148 , accuracy: (training) 0.9143135345666992 ,    (testing) 85.9375\n",
      "[epoch 193] loss: (training) 0.1436932054506678 , (testing) 0.157907695742324 , accuracy: (training) 0.9191820837390458 ,    (testing) 81.25\n",
      "[epoch 194] loss: (training) 0.1428262364296686 , (testing) 0.16019441129174083 , accuracy: (training) 0.9191820837390458 ,    (testing) 80.46875\n",
      "[epoch 195] loss: (training) 0.14310338913641354 , (testing) 0.15656593372114003 , accuracy: (training) 0.9162609542356378 ,    (testing) 81.640625\n",
      "[epoch 196] loss: (training) 0.14271349450473766 , (testing) 0.15166004141792655 , accuracy: (training) 0.9191820837390458 ,    (testing) 85.546875\n",
      "[epoch 197] loss: (training) 0.14277484538024554 , (testing) 0.15782138262875378 , accuracy: (training) 0.9162609542356378 ,    (testing) 81.25\n",
      "[epoch 198] loss: (training) 0.14268664530577074 , (testing) 0.15252443810459226 , accuracy: (training) 0.9172346640701071 ,    (testing) 85.15625\n",
      "[epoch 199] loss: (training) 0.1437490386100969 , (testing) 0.1597825906937942 , accuracy: (training) 0.9152872444011685 ,    (testing) 80.46875\n",
      "[epoch 200] loss: (training) 0.14261887896628608 , (testing) 0.15654328279197216 , accuracy: (training) 0.9152872444011685 ,    (testing) 83.203125\n",
      "[epoch 201] loss: (training) 0.14284978646231114 , (testing) 0.16077888547442853 , accuracy: (training) 0.9162609542356378 ,    (testing) 80.859375\n",
      "[epoch 202] loss: (training) 0.1422885452171804 , (testing) 0.1540006916038692 , accuracy: (training) 0.9201557935735151 ,    (testing) 84.765625\n",
      "[epoch 203] loss: (training) 0.14259913476841096 , (testing) 0.15175053454004228 , accuracy: (training) 0.9211295034079844 ,    (testing) 85.546875\n",
      "[epoch 204] loss: (training) 0.14482210537435014 , (testing) 0.15519437449984252 , accuracy: (training) 0.9172346640701071 ,    (testing) 83.203125\n",
      "[epoch 205] loss: (training) 0.14272849396435933 , (testing) 0.1531662109773606 , accuracy: (training) 0.9162609542356378 ,    (testing) 84.765625\n",
      "[epoch 206] loss: (training) 0.1425501563458679 , (testing) 0.1540962812723592 , accuracy: (training) 0.9172346640701071 ,    (testing) 83.984375\n",
      "[epoch 207] loss: (training) 0.1420638640026541 , (testing) 0.15825496590696275 , accuracy: (training) 0.9191820837390458 ,    (testing) 81.25\n",
      "[epoch 208] loss: (training) 0.14260796897033678 , (testing) 0.1556838935939595 , accuracy: (training) 0.9211295034079844 ,    (testing) 82.8125\n",
      "[epoch 209] loss: (training) 0.14257281789858442 , (testing) 0.15140042989514768 , accuracy: (training) 0.9182083739045764 ,    (testing) 85.9375\n",
      "[epoch 210] loss: (training) 0.1419686377917365 , (testing) 0.15951931208837777 , accuracy: (training) 0.9191820837390458 ,    (testing) 81.640625\n",
      "[epoch 211] loss: (training) 0.14239927312491357 , (testing) 0.1533772696275264 , accuracy: (training) 0.9221032132424537 ,    (testing) 84.765625\n",
      "[epoch 212] loss: (training) 0.14218044347619407 , (testing) 0.1533418686594814 , accuracy: (training) 0.9191820837390458 ,    (testing) 84.765625\n",
      "[epoch 213] loss: (training) 0.14215866936075675 , (testing) 0.1548996608471498 , accuracy: (training) 0.9191820837390458 ,    (testing) 82.8125\n",
      "[epoch 214] loss: (training) 0.14171038192956625 , (testing) 0.15657832799479365 , accuracy: (training) 0.9211295034079844 ,    (testing) 82.03125\n",
      "[epoch 215] loss: (training) 0.14161904731111924 , (testing) 0.1529564141528681 , accuracy: (training) 0.9211295034079844 ,    (testing) 84.765625\n",
      "[epoch 216] loss: (training) 0.1441010440635496 , (testing) 0.15401597053278238 , accuracy: (training) 0.9191820837390458 ,    (testing) 83.984375\n",
      "[epoch 217] loss: (training) 0.14144384000808782 , (testing) 0.15440528036560863 , accuracy: (training) 0.9182083739045764 ,    (testing) 83.984375\n",
      "[epoch 218] loss: (training) 0.14164827041422082 , (testing) 0.1533105968264863 , accuracy: (training) 0.9201557935735151 ,    (testing) 84.765625\n",
      "[epoch 219] loss: (training) 0.1425078438832067 , (testing) 0.1524564161663875 , accuracy: (training) 0.9211295034079844 ,    (testing) 84.765625\n",
      "[epoch 220] loss: (training) 0.14120145401291992 , (testing) 0.15754564991220832 , accuracy: (training) 0.9250243427458618 ,    (testing) 82.03125\n",
      "[epoch 221] loss: (training) 0.1413613301787826 , (testing) 0.15836110664531589 , accuracy: (training) 0.9191820837390458 ,    (testing) 81.640625\n",
      "[epoch 222] loss: (training) 0.14132331741794552 , (testing) 0.15473541046958417 , accuracy: (training) 0.9211295034079844 ,    (testing) 83.59375\n",
      "[epoch 223] loss: (training) 0.14338440377811879 , (testing) 0.16267658467404544 , accuracy: (training) 0.9259980525803311 ,    (testing) 78.90625\n",
      "[epoch 224] loss: (training) 0.14113602149359109 , (testing) 0.1548694632947445 , accuracy: (training) 0.9221032132424537 ,    (testing) 83.203125\n",
      "[epoch 225] loss: (training) 0.14097687738166492 , (testing) 0.15219277481082827 , accuracy: (training) 0.9230769230769231 ,    (testing) 85.15625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 226] loss: (training) 0.14107920427827492 , (testing) 0.15669125400017947 , accuracy: (training) 0.9230769230769231 ,    (testing) 82.8125\n",
      "[epoch 227] loss: (training) 0.14088779615475439 , (testing) 0.15799647220410407 , accuracy: (training) 0.9211295034079844 ,    (testing) 82.8125\n",
      "[epoch 228] loss: (training) 0.14131904491182667 , (testing) 0.15450653480365872 , accuracy: (training) 0.9240506329113924 ,    (testing) 83.984375\n",
      "[epoch 229] loss: (training) 0.1417601254811208 , (testing) 0.1540542122675106 , accuracy: (training) 0.9259980525803311 ,    (testing) 84.375\n",
      "[epoch 230] loss: (training) 0.14073177364060205 , (testing) 0.15707676357124 , accuracy: (training) 0.9240506329113924 ,    (testing) 82.8125\n",
      "[epoch 231] loss: (training) 0.14060844091446914 , (testing) 0.15317558485548943 , accuracy: (training) 0.9259980525803311 ,    (testing) 84.375\n",
      "[epoch 232] loss: (training) 0.14064911184551881 , (testing) 0.1576570450561121 , accuracy: (training) 0.9230769230769231 ,    (testing) 81.640625\n",
      "[epoch 233] loss: (training) 0.14090193412741836 , (testing) 0.15343846986070275 , accuracy: (training) 0.9250243427458618 ,    (testing) 84.375\n",
      "[epoch 234] loss: (training) 0.14058817640685478 , (testing) 0.15561765409074724 , accuracy: (training) 0.9221032132424537 ,    (testing) 82.421875\n",
      "[epoch 235] loss: (training) 0.1402918500038347 , (testing) 0.15934771101456136 , accuracy: (training) 0.9240506329113924 ,    (testing) 81.25\n",
      "[epoch 236] loss: (training) 0.14048025938813494 , (testing) 0.1545806856593117 , accuracy: (training) 0.928919182083739 ,    (testing) 83.984375\n",
      "[epoch 237] loss: (training) 0.14079535114637734 , (testing) 0.15435330825857818 , accuracy: (training) 0.9259980525803311 ,    (testing) 83.984375\n",
      "[epoch 238] loss: (training) 0.14033613460404532 , (testing) 0.15750578313600272 , accuracy: (training) 0.9279454722492697 ,    (testing) 83.59375\n",
      "[epoch 239] loss: (training) 0.1402937362678313 , (testing) 0.15628656756598502 , accuracy: (training) 0.9230769230769231 ,    (testing) 82.8125\n",
      "[epoch 240] loss: (training) 0.14006338233039492 , (testing) 0.1519879272673279 , accuracy: (training) 0.9298928919182083 ,    (testing) 85.546875\n",
      "[epoch 241] loss: (training) 0.1404593933312145 , (testing) 0.15955504588782787 , accuracy: (training) 0.9259980525803311 ,    (testing) 82.03125\n",
      "[epoch 242] loss: (training) 0.14253126393254228 , (testing) 0.16013530176132917 , accuracy: (training) 0.9250243427458618 ,    (testing) 81.640625\n",
      "[epoch 243] loss: (training) 0.14060981833784184 , (testing) 0.15531368530355394 , accuracy: (training) 0.928919182083739 ,    (testing) 82.8125\n",
      "[epoch 244] loss: (training) 0.14076104296771386 , (testing) 0.15490425750613213 , accuracy: (training) 0.9250243427458618 ,    (testing) 83.984375\n",
      "[epoch 245] loss: (training) 0.13997644409030474 , (testing) 0.15541074762586504 , accuracy: (training) 0.9230769230769231 ,    (testing) 82.8125\n",
      "[epoch 246] loss: (training) 0.1405260997332915 , (testing) 0.16043264465406537 , accuracy: (training) 0.9221032132424537 ,    (testing) 81.25\n",
      "[epoch 247] loss: (training) 0.14235553463995165 , (testing) 0.15830087359063327 , accuracy: (training) 0.9279454722492697 ,    (testing) 82.8125\n",
      "[epoch 248] loss: (training) 0.1402228203818448 , (testing) 0.15708250051829964 , accuracy: (training) 0.9259980525803311 ,    (testing) 82.8125\n",
      "[epoch 249] loss: (training) 0.13974266355192927 , (testing) 0.15389340941328555 , accuracy: (training) 0.9279454722492697 ,    (testing) 84.375\n",
      "[epoch 250] loss: (training) 0.14006013167611134 , (testing) 0.1568520403234288 , accuracy: (training) 0.9250243427458618 ,    (testing) 82.8125\n",
      "[epoch 251] loss: (training) 0.1395493503388441 , (testing) 0.15638938068877906 , accuracy: (training) 0.9298928919182083 ,    (testing) 84.375\n",
      "[epoch 252] loss: (training) 0.139498371714174 , (testing) 0.16073482215870172 , accuracy: (training) 0.9318403115871471 ,    (testing) 80.078125\n",
      "[epoch 253] loss: (training) 0.13942843878350292 , (testing) 0.16253771784249693 , accuracy: (training) 0.9318403115871471 ,    (testing) 80.078125\n",
      "[epoch 254] loss: (training) 0.13941797211520063 , (testing) 0.1580570664955303 , accuracy: (training) 0.9279454722492697 ,    (testing) 82.03125\n",
      "[epoch 255] loss: (training) 0.13972605439038735 , (testing) 0.1541240243241191 , accuracy: (training) 0.9308666017526777 ,    (testing) 84.375\n",
      "[epoch 256] loss: (training) 0.13958524646865614 , (testing) 0.1614490372594446 , accuracy: (training) 0.9318403115871471 ,    (testing) 81.25\n",
      "[epoch 257] loss: (training) 0.1397002730355666 , (testing) 0.1593209661077708 , accuracy: (training) 0.9308666017526777 ,    (testing) 81.640625\n",
      "[epoch 258] loss: (training) 0.13992343517156106 , (testing) 0.15635668172035366 , accuracy: (training) 0.9328140214216164 ,    (testing) 83.203125\n",
      "[epoch 259] loss: (training) 0.13925095520862915 , (testing) 0.1573020953219384 , accuracy: (training) 0.9318403115871471 ,    (testing) 82.8125\n",
      "[epoch 260] loss: (training) 0.13928762709665807 , (testing) 0.15855467156507075 , accuracy: (training) 0.9298928919182083 ,    (testing) 82.8125\n",
      "[epoch 261] loss: (training) 0.13948796725713358 , (testing) 0.15777284430805594 , accuracy: (training) 0.9298928919182083 ,    (testing) 82.421875\n",
      "[epoch 262] loss: (training) 0.13992252702615698 , (testing) 0.1531197598669678 , accuracy: (training) 0.9318403115871471 ,    (testing) 84.765625\n",
      "[epoch 263] loss: (training) 0.1396790250513134 , (testing) 0.15699264174327254 , accuracy: (training) 0.9337877312560857 ,    (testing) 83.203125\n",
      "[epoch 264] loss: (training) 0.1394193058053305 , (testing) 0.15464484365656972 , accuracy: (training) 0.9328140214216164 ,    (testing) 85.15625\n",
      "[epoch 265] loss: (training) 0.13884620028172337 , (testing) 0.1564621926518157 , accuracy: (training) 0.9357351509250244 ,    (testing) 84.375\n",
      "[epoch 266] loss: (training) 0.13882038063859337 , (testing) 0.1607655839761719 , accuracy: (training) 0.9308666017526777 ,    (testing) 81.640625\n",
      "[epoch 267] loss: (training) 0.13880439118579016 , (testing) 0.15772899030707777 , accuracy: (training) 0.9308666017526777 ,    (testing) 82.8125\n",
      "[epoch 268] loss: (training) 0.13869451094994392 , (testing) 0.1569320160197094 , accuracy: (training) 0.934761441090555 ,    (testing) 83.984375\n",
      "[epoch 269] loss: (training) 0.13955720653802706 , (testing) 0.16065328347031027 , accuracy: (training) 0.9308666017526777 ,    (testing) 82.421875\n",
      "[epoch 270] loss: (training) 0.1384622844477321 , (testing) 0.15713071811478585 , accuracy: (training) 0.9337877312560857 ,    (testing) 83.203125\n",
      "[epoch 271] loss: (training) 0.1385564563109877 , (testing) 0.15079965349286795 , accuracy: (training) 0.9386562804284323 ,    (testing) 86.328125\n",
      "[epoch 272] loss: (training) 0.13852487161277682 , (testing) 0.15075980324763805 , accuracy: (training) 0.9386562804284323 ,    (testing) 86.328125\n",
      "[epoch 273] loss: (training) 0.13847247403263468 , (testing) 0.15922244440298527 , accuracy: (training) 0.9318403115871471 ,    (testing) 81.25\n",
      "[epoch 274] loss: (training) 0.13815862047544836 , (testing) 0.15995092445518821 , accuracy: (training) 0.934761441090555 ,    (testing) 80.859375\n",
      "[epoch 275] loss: (training) 0.1386795149658118 , (testing) 0.1581818099366501 , accuracy: (training) 0.9367088607594937 ,    (testing) 83.203125\n",
      "[epoch 276] loss: (training) 0.13828767872296918 , (testing) 0.15618390240706503 , accuracy: (training) 0.934761441090555 ,    (testing) 82.421875\n",
      "[epoch 277] loss: (training) 0.13851272266274872 , (testing) 0.16081592440605164 , accuracy: (training) 0.9357351509250244 ,    (testing) 80.46875\n",
      "[epoch 278] loss: (training) 0.13828520570945926 , (testing) 0.15620477101765573 , accuracy: (training) 0.934761441090555 ,    (testing) 83.59375\n",
      "[epoch 279] loss: (training) 0.1386355737439629 , (testing) 0.15586136223282665 , accuracy: (training) 0.937682570593963 ,    (testing) 83.59375\n",
      "[epoch 280] loss: (training) 0.13845114411371676 , (testing) 0.15644126036204398 , accuracy: (training) 0.9406037000973709 ,    (testing) 82.8125\n",
      "[epoch 281] loss: (training) 0.13818505985627946 , (testing) 0.16036893089767545 , accuracy: (training) 0.937682570593963 ,    (testing) 80.46875\n",
      "[epoch 282] loss: (training) 0.1390120819486149 , (testing) 0.15646259975619614 , accuracy: (training) 0.937682570593963 ,    (testing) 82.8125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 283] loss: (training) 0.13791591525657068 , (testing) 0.1596701688831672 , accuracy: (training) 0.9357351509250244 ,    (testing) 80.859375\n",
      "[epoch 284] loss: (training) 0.1378990654753063 , (testing) 0.15602177660912275 , accuracy: (training) 0.9406037000973709 ,    (testing) 82.8125\n",
      "[epoch 285] loss: (training) 0.13782505669329673 , (testing) 0.15542076516430825 , accuracy: (training) 0.9367088607594937 ,    (testing) 83.59375\n",
      "[epoch 286] loss: (training) 0.13764294034885596 , (testing) 0.14987868361640722 , accuracy: (training) 0.9425511197663097 ,    (testing) 85.9375\n",
      "[epoch 287] loss: (training) 0.13771741722137518 , (testing) 0.1602373415371403 , accuracy: (training) 0.937682570593963 ,    (testing) 80.46875\n",
      "[epoch 288] loss: (training) 0.13878288737654804 , (testing) 0.14896144182421267 , accuracy: (training) 0.937682570593963 ,    (testing) 86.328125\n",
      "[epoch 289] loss: (training) 0.1376785606985769 , (testing) 0.1541588215623051 , accuracy: (training) 0.9406037000973709 ,    (testing) 84.765625\n",
      "[epoch 290] loss: (training) 0.13779560643799452 , (testing) 0.1594392245169729 , accuracy: (training) 0.9386562804284323 ,    (testing) 82.421875\n",
      "[epoch 291] loss: (training) 0.13750543211477262 , (testing) 0.15615029237233102 , accuracy: (training) 0.937682570593963 ,    (testing) 82.421875\n",
      "[epoch 292] loss: (training) 0.1377924950929147 , (testing) 0.16311739722732455 , accuracy: (training) 0.9444985394352483 ,    (testing) 79.6875\n",
      "[epoch 293] loss: (training) 0.13735286258631707 , (testing) 0.15596608573105186 , accuracy: (training) 0.937682570593963 ,    (testing) 84.765625\n",
      "[epoch 294] loss: (training) 0.13735381446496392 , (testing) 0.15831095073372126 , accuracy: (training) 0.9386562804284323 ,    (testing) 83.203125\n"
     ]
    }
   ],
   "source": [
    "num_classes = 2\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# load neural network model\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "model = Linear(num_classes=num_classes)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Set the flag for using cuda\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "bCuda = 0\n",
    "\n",
    "if bCuda:\n",
    " \n",
    "    model.cuda()\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# optimization algorithm\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "optimizer   = optim.SGD(model.parameters(), lr=0.015, weight_decay=0.02)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=1, min_lr=2e-4, verbose=1)\n",
    "objective   = nn.CrossEntropyLoss()\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# function for training the model\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def train():\n",
    "\n",
    "    # print('train the model at given epoch')\n",
    "    accuracy_train = []\n",
    "    loss_train = []\n",
    "    correct = 0\n",
    "    correct_batch = 0\n",
    "\n",
    "    model.train()\n",
    "    for idx_batch, (data, target) in enumerate(trainloader):\n",
    "\n",
    "        if bCuda:\n",
    "        \n",
    "            data, target    = data.cuda(), target.cuda()\n",
    "\n",
    "        data, target    = Variable(data), Variable(target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output  = model(data)\n",
    "        loss    = objective(output, target)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_train_batch    = loss.item() / len(data)\n",
    "        loss_train.append(loss_train_batch)\n",
    "        pred        = output.data.max(1)[1]\n",
    "        correct     += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "        correct_batch = pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "        accuracy_train_batch = float(correct_batch) / len(data)\n",
    "        accuracy_train.append(accuracy_train_batch)\n",
    "        \n",
    "    loss_train_mean     = np.mean(loss_train)\n",
    "    loss_train_std      = np.std(loss_train)\n",
    "    accuracy_train_mean   = float(correct) / len(trainloader.dataset)  # mean accuracy\n",
    "    accuracy_train_std  = np.std(accuracy_train)\n",
    "\n",
    "    return {'loss_train_mean': loss_train_mean, 'loss_train_std': loss_train_std, 'accuracy_train_mean' : accuracy_train_mean, 'accuracy_train_std' : accuracy_train_std}\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# function for testing the model\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def test():\n",
    "\n",
    "    # print('test the model at given epoch')\n",
    "\n",
    "    accuracy_test   = []\n",
    "    loss_test       = 0\n",
    "    correct         = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    for idx_batch, (data, target) in enumerate(valloader):\n",
    "\n",
    "        if bCuda:\n",
    "        \n",
    "            data, target    = data.cuda(), target.cuda()\n",
    "\n",
    "        data, target    = Variable(data), Variable(target)\n",
    "\n",
    "        output  = model(data)\n",
    "        loss    = objective(output, target)\n",
    "\n",
    "        loss_test   += loss.item()\n",
    "        pred        = output.data.max(1)[1]\n",
    "        correct     += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    loss_test       = loss_test / len(valloader.dataset)\n",
    "    accuracy_test   = 100. * float(correct) / len(valloader.dataset)\n",
    "\n",
    "    return {'loss_test': loss_test, 'accuracy_test': accuracy_test}\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# iteration for the epoch\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "loss_train_mean, loss_train_std, loss_test, accuracy_test, accuracy_train_mean, accuracy_train_std = [], [], [], [], [], []\n",
    "loss_temp = 0;\n",
    "\n",
    "for e in range(3000):\n",
    "    \n",
    "    result_train    = train()\n",
    "    result_test     = test()\n",
    "    scheduler.step(result_test['loss_test'], e)\n",
    "\n",
    "    \n",
    "    loss_train_mean.append(result_train['loss_train_mean'])\n",
    "    loss_train_std.append(result_train['loss_train_std'])\n",
    "    loss_test.append(result_test['loss_test'])\n",
    "    accuracy_test.append(result_test['accuracy_test'])\n",
    "    accuracy_train_mean.append(result_train['accuracy_train_mean'])\n",
    "    accuracy_train_std.append(result_train['accuracy_train_std'])\n",
    "    \n",
    "    print(f\"[epoch {e}] loss: (training) {loss_train_mean[-1]} , (testing) {loss_test[-1]} , accuracy: (training) {result_train['accuracy_train_mean']} ,    (testing) {accuracy_test[-1]}\")\n",
    "    \n",
    "    if(abs(loss_temp - loss_train_mean[-1]) < 10e-7):\n",
    "        break;\n",
    "    loss_temp = loss_train_mean[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(loss_train_mean)\n",
    "plt.plot(loss_test)\n",
    "plt.fill_between(np.arange(1,len(loss_train_mean)+1), np.array(loss_train_mean) - np.array(loss_train_std),np.array(loss_train_mean) + np.array(loss_train_std), alpha = 0.3)\n",
    "plt.legend(['loss_train_mean','loss_test'])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.title(\"Accuracy\")\n",
    "plt.plot(accuracy_train_mean)\n",
    "plt.plot(accuracy_test)\n",
    "plt.fill_between(np.arange(1,len(accuracy_train_mean)+1), np.array(accuracy_train_mean) - np.array(accuracy_train_std),np.array(accuracy_train_mean) + np.array(accuracy_train_std), alpha = 0.3)\n",
    "plt.legend(['accuracy_train_mean','accuracy_test'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  dataset     |           loss           |          accuracy         |\n",
      "----------------------------------------------------------------------\n",
      "   train      |       0.1373538145       |       0.1583109507        |\n",
      "----------------------------------------------------------------------\n",
      "   test       |       0.1583109507       |       83.2031250000        |\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"  dataset     |           loss           |          accuracy         |\")\n",
    "print(\"----------------------------------------------------------------------\")\n",
    "print(\"   train      |       %.10f       |       %.10f        |\"%(loss_train_mean[-1],accuracy_train_mean[-1]))\n",
    "print(\"----------------------------------------------------------------------\")\n",
    "print(\"   test       |       %.10f       |       %.10f        |\"%(loss_test[-1],accuracy_test[-1]))\n",
    "print(\"----------------------------------------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
